---
published: true
layout: post
title: "밑바닥부터 시작하는 딥러닝 Chapter07"
categories: [ML]
tags: [Deep_learning]
math: true
sitemap: false
---

# Chapter 7 합성곱 신경망(CNN)

## 7.1 전체 구조

CNN에서 등장하는 새로운 layer
- 합성곱 계층(convolutional layer)
- 풀링 계층(pooling layer)

현재까지 봤던 신경망을 완전연결(fully-connected)라고 하며 Affine 계층으로 구현했다. Affine 계층 뒤에는 활성화 함수로 ReLU 혹은 Sigmoid를 사용했다.

CNN의 구조는 새로운 합성곱 계층(Conv)과 풀링 계층(pooling)이 추가된다. Conv-ReLU-(Pooling)의 흐름이다. 출력층과 가까운 층의 경우에는 Affine-ReLU, 출력층은 Affine-Softmax 조합을 그대로 사용한다.

<img src="https://t1.daumcdn.net/cfile/tistory/2409463658F46CAD1F">
<center><small>▲ 완전연결 계층(위), CNN(아래)</small></center>

## 7.2 합성곱 계층

- 패딩(padding)
- 스트라이드(stride)
- 입체적인 데이터 흐름

### 7.2.1 완전연결 계층의 문제점

데이터의 형상이 무시된다.
- 완전연결 계층의 입력은 평탄화 필요
- 본래 다차원인 데이터의 경우 다차원에서 특별한 정보가 담겨있을 가능성이 있다.
- 이미지의 경우
    - 가로, 세로, 색상의 3차원 데이터
    - 공간적 정보
    

반면, 합성곱 계층은 형상을 유지한다.
- 입력 데이터가 형상 그대로 들어온다.
- 다음 계층으로 전달될 때도 그대로 전달
- 다차원의 형상을 가진 데이터를 올바르게 이해할 수 있다.
- 특징 맵(feature map): 합성곱 계층의 입출력 데이터
    - 입력 특징 맵(input feature map)
    - 출력 특징 맵(output feature map)

### 7.2.2 합성곱 연산

합성곱 연산 = 필터 연산


합성곱 연산 예제
<img src="https://t1.daumcdn.net/cfile/tistory/2764173558F475B42C">

데이터 설명
- 입력 데이터: (4,4)의 높이와 너비를 가진 형상
- 필터: (3,3)의 높이와 너비를 가진 형상
    - 커널이라고도 한다.
- 출력: (2,2)의 놆이와 너비를 가진 형상

연산 과정
1. 필터의 **윈도우(window)**를 일정 간격으로 이동하면서 입력 데이터에 적용
2. 단일 곱셈-누산(fused multiply-add, FMA): 대응하는 원소기리 곱한 후 모두 더함
3. 결과를 출력의 해당 장소에 저장
4. 모든 장소에서 수행

가중치와 편향
- 가중치: 필터의 매개변수
- 편향: 필터를 적용한 후 데이터에 더해진다. 항상 하나(1X1)만 존재

### 7.2.3 패딩

패딩(padding)
- 입력 데이터 주변을 특정 값으로 채우는 것
- 예를 들어 0으로

패딩의 예

<img src="https://t1.daumcdn.net/cfile/tistory/2527FA3758F4785B13">

- 입력데이터: 4X4
- 패딩 후: 6X6
- 3X3 필터 적용 후: 4X4

패딩을 하는 이유
- 출력 크기를 조정하는 목적
- 합성곱 신경망에서 그냥 필터를 적용하면 계속해서 크기가 줄어든다. 신경망이 깊어지면 어느 순간 크기가 1이 되어버린다. 이는 더이상 합성곱을 할 수 없는 상태이기 때문에 문제가 된다.
- 풀링을 하면 출력 크기를 유지시켜 줄 수 있어서, 입력 데이터의 공간적 크기를 고정해서 다음 층으로 넘겨줄 수 있다.

### 7.2.4 스트라이드

스트라이드
- 필터를 적용하는 위치 간격
- 스트라이드를 키우면 출력 크기가 작아진다.

<img src="https://2.bp.blogspot.com/-vtZW1-cBQGg/WYJrUnBjRiI/AAAAAAAALNY/GhTnu5QDi3M4NHB_FiyOJAjy58mTkzlYwCK4BGAYYCw/s320/o9.PNG">
<center><small>▲ 스트라이드가 2인 합성곱 신경망</small></center>

패딩, 스트라이드, 출력 크기 계산
- 입력 크기: $(H, W)$
- 필터 크기: $(FH, FW)$
- 출력 크기: $(OH, OW)$
- 패딩: $P$
- 스트라이드: $S$

$$OH = \frac {H + 2P - FH} S + 1$$

$$OW = \frac {W + 2P - FW} S + 1$$

주의
- 계산 결과가 정수로 나누어 떨어져야 한다.

### 7.2.5 3차원 데이터의 합성곱 연산

3차원 데이터의 합성곱 연산 예

<img src="https://t1.daumcdn.net/cfile/tistory/99C185405BC97F4D1E">

- 입력 데이터의 채널 수 = 필터의 채널 수
- 필터의 크기는 원하는 크기로(모든 채널의 필터 크기는 같아야 함)

### 7.2.6 블록으로 생각하기

<img src="https://t1.daumcdn.net/cfile/tistory/998CE7355BC97F632E">

- 데이터와 필터의 형상: (채널, 높이, 너비)
- 출력: 채널이 1개인 특징 맵

<img src="https://t1.daumcdn.net/cfile/tistory/99CDF2395BC97F7C2D">

- 필터를 여러 개 사용하면 출력의 채널 수도 늘어남
- 이 출력을 다음 층으로 넘겨준다.
- 필터의 가중치 데이터는 4차원: (출력 채널 수, 입력 채널 수, 높이, 너비)
- 편향: 채널당 하나의 값

### 7.2.7 배치 처리

<img src="https://t1.daumcdn.net/cfile/tistory/99E4C84E5C4D31B728">

- 4차원으로 데이터 저장: (데이터 수, 채널 수, 높이, 너비)
- 가장 앞쪽에 배치용 차원을 추가
- 각 흐름마다 N번의 합성곱 연산을 수행
- 배치 처리의 효과는 완전연결 신경망과 동일

## 7.3 풀링 계층

풀링 계층
- 가로, 세로 방향의 공간을 줄이는 연산

풀링의 예

<img src="https://t1.daumcdn.net/cfile/tistory/993A5B465C4D32D32C">

- 최대 풀링(max pooling)
    - 대상 영역 내에서 최대값을 구하는 연산
- 평균 풀링(average pooling)
    - 대상 영역의 평균을 계산
- 이미지 인식 분야에서는 최대 풀링을 사용
- 윈도우 크기와 스트라이드는 동일한 값으로 하는 것이 일반적
    - 위의 예: 윈도우 2X2, 스트라이드 2

### 7.3.1 풀링 계층의 특징

학습해야 할 매개변수가 없다.

채널 수가 변하지 않는다.
- 채널마다 독립적으로 계산하기 때문

입력의 변화에 영향을 적게 받는다(강건하다).
- 입력 데이터가 조금 변해도 풀링 결과는 잘 변하지 않는다.

## 7.4 합성곱/풀링 계층 구현하기

### 7.4.1 4차원 배열

CNN에서 흐르는 데이터는 4차원이다.


```python
import numpy as np
```


```python
x = np.random.rand(10, 1, 28, 28)
x.shape
```




    (10, 1, 28, 28)




```python
# 첫번째 데이터에 접근
x[0].shape
```




    (1, 28, 28)




```python
# 두번째 데이터에 접근
x[1].shape
```




    (1, 28, 28)




```python
# 첫번째 데이터의 첫 채널에 접근
x[0,0]
```




    array([[9.44322204e-01, 1.61725959e-01, 4.97299575e-01, 4.90849763e-01,
            2.69806956e-01, 4.80739959e-01, 5.33766630e-01, 3.52483845e-01,
            5.90821168e-01, 5.07826272e-01, 6.40826973e-01, 4.59954326e-01,
            5.82373841e-01, 6.52799925e-02, 3.35695899e-01, 4.61650460e-01,
            8.95937799e-01, 6.28431996e-02, 6.36711673e-01, 5.50039978e-01,
            8.44648519e-01, 4.38516371e-01, 5.49044826e-01, 8.53925508e-01,
            1.25532691e-01, 9.38128354e-01, 3.10436399e-01, 6.31229430e-02],
           .......
           ,
           [1.09660007e-01, 3.29975706e-01, 6.27062235e-01, 2.80376880e-02,
            3.70181133e-01, 2.82339621e-01, 2.81632554e-01, 1.34358950e-01,
            5.66760294e-01, 2.94240600e-01, 5.15104998e-01, 1.93230444e-02,
            5.47469657e-01, 2.10305031e-01, 3.66689889e-02, 5.87465571e-01,
            3.07306557e-01, 8.89560760e-01, 5.15682357e-01, 8.76126342e-01,
            7.75768722e-01, 9.25446546e-01, 3.85371285e-01, 7.81498205e-01,
            1.90269789e-01, 9.38474719e-01, 1.95191469e-01, 8.50734947e-01]])



### 7.4.2 im2col로 데이터 전개하기

넘파이에서 원소를 접근할 때 for 문을 사용하지 않는 것이 바람직하다.

im2col 함수

<img src="https://t1.daumcdn.net/cfile/tistory/99F49B495BA49CE71C">

- 입력 데이터를 필터링(가중치 계산)하기 좋게 펼치는 함수
- 입력 데이터에서 필터를 적용하는 영역을 한 줄로 늘어 놓는다.
- 필터를 적용하는 영역이 겹쳐서 메모리를 더 많이 사용하지만, 선형 대수 라이브러리가 행렬 계산을 매우 빠르게 처리해줘서 속도에서는 이점이 있다.
- Affine 계층에서 한 것과 유사한 계산
- 마지막에 2차원 출력 데이터를 4차원으로 변형(reshape)

### 7.4.3 합성곱 계층 구현하기


```python
# 필터 크기, 스트라이드, 패딩을 고려해서 입력 데이터를 2차원 배열로 전개
def im2col(input_data, filter_h, filter_w, stride=1, pad=0):
    """다수의 이미지를 입력받아 2차원 배열로 변환한다(평탄화).
    
    Parameters
    ----------
    input_data : 4차원 배열 형태의 입력 데이터(이미지 수, 채널 수, 높이, 너비)
    filter_h : 필터의 높이
    filter_w : 필터의 너비
    stride : 스트라이드
    pad : 패딩
    
    Returns
    -------
    col : 2차원 배열
    """
    N, C, H, W = input_data.shape
    out_h = (H + 2*pad - filter_h)//stride + 1
    out_w = (W + 2*pad - filter_w)//stride + 1

    # np.pad(array, pad_width, mode, **kwargs)
    # array: 패딩할 배열
    # pad_width: 각 축마다 패딩할 값의 수
    # mode: 패딩 방식
    # default로 0으로 패딩
    # 신경망에서 패딩을 하게 되면 이미지와 채널 수에 해당되는 차원은 하지 않기 때문에 pad_width에 해당되는
    # 인수의 처음과 두번째 원소가 (0,0)인 것이다. 즉, 해당 차원은 패딩하지 않는다.
    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')
    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))

    # Q. for 문 이해 안됨
    for y in range(filter_h):
        y_max = y + stride*out_h
        for x in range(filter_w):
            x_max = x + stride*out_w
            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]

    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)
    return col
```


```python
import sys, os
sys.path.append(os.pardir)
from common.util import im2col
```


```python
x1 = np.random.rand(1, 3, 7, 7)
col1 = im2col(x1, 5, 5, stride=1, pad=0)
print(col1.shape)
```

    (9, 75)



```python
x2 = np.random.rand(10, 3, 7, 7)
col2 = im2col(x2, 5, 5, stride=1, pad=0)
print(col2.shape)
```

    (90, 75)



```python
class Convolution:
    
    def __init__(self, W, b, stride=1, pad=0):
        self.W = W
        self.b = b
        self.stride = stride
        self.pad = pad
        
    
    def forward(self, x):
        FN, C, FH, FW = self.W.shape
        N, C, H, W = x.shape
        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)
        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)
        
        col = im2col(x, FH, FW, self.stride, self.pad)
        col_W = self.W.shape(FN, -1). T
        out = np.dot(col, col_W) + self.b
        
        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)
        
        return out
```

역전파에서는 im2col을 반대로 처리하는 col2im을 사용한다.


```python
def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):
    """(im2col과 반대) 2차원 배열을 입력받아 다수의 이미지 묶음으로 변환한다.
    
    Parameters
    ----------
    col : 2차원 배열(입력 데이터)
    input_shape : 원래 이미지 데이터의 형상（예：(10, 1, 28, 28)）
    filter_h : 필터의 높이
    filter_w : 필터의 너비
    stride : 스트라이드
    pad : 패딩
    
    Returns
    -------
    img : 변환된 이미지들
    """
    N, C, H, W = input_shape
    out_h = (H + 2*pad - filter_h)//stride + 1
    out_w = (W + 2*pad - filter_w)//stride + 1
    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)

    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))
    for y in range(filter_h):
        y_max = y + stride*out_h
        for x in range(filter_w):
            x_max = x + stride*out_w
            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]

    return img[:, :, pad:H + pad, pad:W + pad]
```

### 7.4.4 풀링 계층 구현하기

<img src="https://t1.daumcdn.net/cfile/tistory/992F044B5C4D422B02">
<img src="https://t1.daumcdn.net/cfile/tistory/99C888485C4D425402">

합성곱 계층과 마찬가지로 im2col 함수를 이용한다. 다만, 다른 점은 채널마다 독립적으로 전개한다는 점이다.


```python
class Pooling:
    
    def __init__(self, pool_h, pool_w, stride=1, pad=0):
        self.pool_h = pool_h
        self.pool_w = pool_w
        self.stride = stride
        self.pad = pad
        
    
    def forward(self, x):
        N, C, H, W = x.shape
        out_h = int(1 + (H - self.pool_h) / self.stride)
        out_w = int(1 + (W - self.pool_w) / self.stride)
        
        # 전개 (1)
        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)
        col = col.reshape(-1, self.pool_h*self.pool_w)
        
        # 최댓값 (2)
        out = np.max(col, axis=1)
        
        # 성형 (3)
        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)
        
        return out
```

## 7.5 CNN 구현하기

손글씨 숫자 인식하는 CNN 구현
- 구조: conv-relu-pooling-affine-relu-affine-softmax

SimpleConvNet 클래스
- \_\_init\_\_
    - 인수
        - input_dim: 입력 데이터(채널 수, 높이, 너비)의 차원
        - conv_param: 합성곱 계층의 하이퍼파라미터(딕셔너리)
            - filter_num: 필터 수
            - filter_size: 필터 크기
            - stride: 스트라이드
            - pad: 패딩
            - hidden_size: 은닉층의 뉴런 수
            - output_size: 출력층의 뉴런 수
            - weight_init_std: 초기화 때의 가중치 표준편차


```python
class SimpleConvNet:
    
    def __init__(self, input_dim=(1, 28, 28),
                conv_param={'filter_num':30, 'filter_size':5,
                           'pad':0, 'stride':1},
                hidden_size=100, output_size=10, weight_init_std=0.01):
        filter_num = conv_param['filter_num']
        filter_size = conv_param['filter_size']
        filter_pad = conv_param['pad']
        filter_stride = conv_param['stride']
        input_size = input_dim[1]
        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1
        pool_output_size = int((filter_num * (conv_output_size/2) * (conv_output_size/2)))
        
        self.params = {}
        self.params['W1'] = weight_init_std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size)
        self.params['b1'] = np.zeros(filter_num)
        self.params['W2'] = weight_init_std * np.random.randn(pool_output_size, hidden_size)
        self.params['b2'] = np.zeros(hidden_size)
        self.params['W3'] = weight_init_std * np.random.randn(hidden_size, output_size)
        self.params['b3'] = np.zeros(output_size)
        
        self.layers = OrderedDict()
        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],
                                          conv_param['stride'], conv_param['pad'])
        self.layers['Relu1'] = Relu()
        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)
        self.layers['Affine1'] = Affine(self.parmas['W2'], self.params['b2'])
        self.layers['Relu2'] = Relu()
        self.laeyrs['Affine2'] = Affine(self.params['W3'], self.parmas['b3'])
        self.last_layer = SoftmaxWithLoss()
        
    
    def predict(self, x):
        for layer in self.layers.values():
            x = layers.forward(x)
        
        return x
    
    
    def loss(self, x, t):
        y = self.predict(x)
        
        return self.last_layer.forward(y, t)
    
    
    def gradient(self, x, t):
        # 순전파
        self.loss(x, t)
        
        # 역전파
        dout = 1
        dout = self.last_layer.backward(dout)
        
        layers = list(self.layers.values())
        layers.reverse()
        for layer in layers:
            dout = layer.backward(dout)
            
        # 결과 저장
        grads = {}
        grads['W1'] = self.layers['Conv1'].dW
        grads['b1'] = self.layers['Conv1'].db
        grads['W2'] = self.layers['Affine1'].dW
        grads['b2'] = self.layers['Affine1'].db
        grads['W3'] = self.layers['Affine2'].dW
        grads['b3'] = self.layers['Affine'].db
        
        return grads
```


```python
# coding: utf-8
import sys, os
sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정
import numpy as np
import matplotlib.pyplot as plt
from dataset.mnist import load_mnist
from simple_convnet import SimpleConvNet
from common.trainer import Trainer

# 데이터 읽기
(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)

# 시간이 오래 걸릴 경우 데이터를 줄인다.
#x_train, t_train = x_train[:5000], t_train[:5000]
#x_test, t_test = x_test[:1000], t_test[:1000]

max_epochs = 20

network = SimpleConvNet(input_dim=(1,28,28), 
                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},
                        hidden_size=100, output_size=10, weight_init_std=0.01)
                        
trainer = Trainer(network, x_train, t_train, x_test, t_test,
                  epochs=max_epochs, mini_batch_size=100,
                  optimizer='Adam', optimizer_param={'lr': 0.001},
                  evaluate_sample_num_per_epoch=1000)
trainer.train()

# 매개변수 보존
network.save_params("params.pkl")
print("Saved Network Parameters!")

# 그래프 그리기
markers = {'train': 'o', 'test': 's'}
x = np.arange(max_epochs)
plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)
plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)
plt.xlabel("epochs")
plt.ylabel("accuracy")
plt.ylim(0, 1.0)
plt.legend(loc='lower right')
plt.show()
```

    train loss:2.2995260237545354
    === epoch:1, train acc:0.131, test acc:0.118 ===
    train loss:2.2975321648494162
    train loss:2.294610007994603
    train loss:2.287643742679368
    train loss:2.277571750143067
    train loss:2.273888829395921
    train loss:2.25138555721259
    train loss:2.231636338533291
    .....
    train loss:0.0007504085776238781
    train loss:0.0006305754900100426
    train loss:3.650351210427843e-05
    train loss:0.00011660007186879213
    train loss:0.0034911552723316595
    train loss:2.7817370077523596e-05
    train loss:0.00278068868231808
    train loss:0.00860630414349712
    train loss:0.000212820545808942
    train loss:0.0041047099315977015
    train loss:0.0023794835160068843
    train loss:0.0026915451634738257
    train loss:0.00011453829850605189
    train loss:0.0023212412777749184
    train loss:4.672228737306881e-05
    train loss:0.0005770183132382689
    train loss:3.998510631355986e-05
    train loss:0.0012251012653243113
    train loss:0.001225842621761431
    train loss:0.00018016703930926606
    train loss:0.0011863858625609006
    train loss:0.00020601261406510895
    train loss:0.020417215290379324
    train loss:0.00020197674243562533
    train loss:0.006390657381187902
    train loss:0.00010603314122986489
    train loss:0.00037329694319883177
    train loss:0.0036877658448098848
    train loss:0.0006094631970039707
    train loss:0.00047120910979439585
    train loss:0.00019528056770125042
    train loss:0.0001959878676012942
    train loss:0.0003382110604612978
    train loss:0.0015579024218455577
    train loss:0.0026843087959261287
    train loss:0.013432609885665527
    train loss:0.001941956277535325
    train loss:0.0001861940532349634
    train loss:0.0027816507925776707
    train loss:0.001876821975816105
    train loss:0.0008053180855204114
    train loss:0.0022498999334715497
    train loss:0.0004023503025203104
    train loss:0.002829371045887539
    train loss:0.006198255683125497
    train loss:0.0013390517584302966
    train loss:0.0016573133599115631
    train loss:0.001934521872157699
    train loss:0.0010795976011183056
    =============== Final Test Accuracy ===============
    test acc:0.9863
    Saved Network Parameters!






## 7.6 CNN  시각화하기

### 7.6.1 1번째 층의 가중치 시각화하기


```python
# coding: utf-8
import numpy as np
import matplotlib.pyplot as plt
from simple_convnet import SimpleConvNet

def filter_show(filters, nx=8, margin=3, scale=10):
    """
    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py
    """
    FN, C, FH, FW = filters.shape
    ny = int(np.ceil(FN / nx))

    fig = plt.figure()
    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)

    for i in range(FN):
        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])
        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')
    plt.show()


network = SimpleConvNet()
# 무작위(랜덤) 초기화 후의 가중치
filter_show(network.params['W1'])

# 학습된 가중치
network.load_params("params.pkl")
filter_show(network.params['W1'])
```




![다운로드](/assets/images/2022-01-02-Chapter7/다운로드.png)




무엇을 보고 있는 것일까?
- 에지(색상이 바뀐 경계선), 블롭(국소적으로 덩어리진 영역) 등
- 예: 세로 에지(필터1)과 가로 에지(필터2)에 반응하는 필터
<img src="https://t1.daumcdn.net/cfile/tistory/999F114D5C4D500610">
- 초기 계층에서 필터는 원시적인 정보를 추출한다.

### 7.6.2 층 깊이에 따른 추출 정보 변화

- 계층이 깊어질수록 추출되는 정보(강하게 반응하는 뉴런)는 더 추상화된다.
- 예: AlexNet
    - 일반 사물 인식 8층 CNN
    - 마지막 층은 완전연결 계층
    - 1층: 에지와 블롭, 3층 텍스쳐, 5층: 사물의 일부, 마지막층: 사물의 클래스에 주로 반응
    - 깊어질 수록 사물의 의미를 이해하도록 변화
    <img src="https://t1.daumcdn.net/cfile/tistory/99AF37505C4D514115">

## 7.7 대표적인 CNN

### 7.7.1 LeNet

<img src="https://t1.daumcdn.net/cfile/tistory/99145F445C4D51F114">

- CNN의 원조
- 손글씨 숫자 인식 네트워크
- 합성곱과 서브 샘플링 계층 반복
    - 현재는 서브 샘플링 대신 최대 풀링
    - 서브 샘플링은 2X2 필터로 average pooling
- 마지막 층: 완전연결 계층
- 활성화 함수: sigmoid
    - 현재는 주로 ReLU 함수 사용

### 7.7.2 AlexNet

<img src="https://t1.daumcdn.net/cfile/tistory/99B4DA3B5C4D52B515">

- 딥러닝 돌풍의 주역
- LeNet과 큰 구조에서는 유사
- 변경점
    - 활성화 함수: ReLU
    - LRN(local response normalization): 국소적 정규화 계층
    - 드롭아웃
    

딥러닝의 발전 원동력은?
- 빅데이터
- GPU
