<!DOCTYPE html><html lang="ko" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="밑바닥부터 시작하는 딥러닝 Chapter05" /><meta property="og:locale" content="ko" /><meta name="description" content="수치 미분은 시간이 오래 걸리는 단점이 있다. 오차역전파법(backpropagation)은 효율적 계산이 가능하다." /><meta property="og:description" content="수치 미분은 시간이 오래 걸리는 단점이 있다. 오차역전파법(backpropagation)은 효율적 계산이 가능하다." /><link rel="canonical" href="https://leeje008.github.io/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter05/" /><meta property="og:url" content="https://leeje008.github.io/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter05/" /><meta property="og:site_name" content="Yh’s blog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-11-25T00:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="밑바닥부터 시작하는 딥러닝 Chapter05" /><meta name="twitter:site" content="@twitter_username" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2021-11-25T00:00:00+09:00","datePublished":"2021-11-25T00:00:00+09:00","description":"수치 미분은 시간이 오래 걸리는 단점이 있다. 오차역전파법(backpropagation)은 효율적 계산이 가능하다.","headline":"밑바닥부터 시작하는 딥러닝 Chapter05","mainEntityOfPage":{"@type":"WebPage","@id":"https://leeje008.github.io/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter05/"},"url":"https://leeje008.github.io/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter05/"}</script><title>밑바닥부터 시작하는 딥러닝 Chapter05 | Yh's blog</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Yh's blog"><meta name="application-name" content="Yh's blog"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="/assets/img/me3.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Yh's blog</a></div><div class="site-subtitle font-italic">Final success will be made repeated attempts</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/leeje008" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['leeje008','naver.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="https://www.facebook.com/profile.php?id=100006983951106" aria-label="facebook" > <i class="fab fa-facebook"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>밑바닥부터 시작하는 딥러닝 Chapter05</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4 pb-5"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>밑바닥부터 시작하는 딥러닝 Chapter05</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1637766000" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Nov 25, 2021 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="https://github.com/leeje008">Koyounghun</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="3004 words"> <em>16 min</em> read</span></div></div></div><div class="post-content"><p>수치 미분은 시간이 오래 걸리는 단점이 있다. 오차역전파법(backpropagation)은 효율적 계산이 가능하다.</p><ul><li>수식을 통한 이해<li>계산 그래프를 통한 이해 ★</ul><p>참고</p><ul><li>http://karpathy.github.io/<li>Stanford CS231n</ul><h2 id="51-계산-그래프"><span class="mr-2">5.1 계산 그래프</span><a href="#51-계산-그래프" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><strong>계산 그래프(computational graph)</strong>는 계산 과정을 그래프로 나타낸 것이다. 그래프는 <strong>노드(node)</strong>와 <strong>에지(edge)</strong>로 표현된다.</p><h3 id="511-계산-그래프로-풀다"><span class="mr-2">5.1.1 계산 그래프로 풀다</span><a href="#511-계산-그래프로-풀다" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><img data-src="https://t1.daumcdn.net/cfile/tistory/997ED34B5B98F5F235" data-proofer-ignore></p><center><small>▲ 간단한 계산 그래프</small></center><p>계산 그래프 문제 흐름</p><ol><li>계산 그래프를 구성한다.<li>그래프에서 계산을 왼쪽에서 오른쪽으로 진행한다.</ol><p>계산을 왼쪽에서 오른쪽으로 진행하는 단계를 <strong>순전파(forward propagation)</strong>이라고 하고 반대 방향을 <strong>역전파(backward propagation)</strong>이라고 한다.</p><h3 id="512-국소적-계산"><span class="mr-2">5.1.2 국소적 계산</span><a href="#512-국소적-계산" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>계산 그래프는 국소적 계산을 전파해서 최종 결과를 얻을 수 있다는 특징이 있다. 즉, 다른 부분은 상관하지 않고 자신과 관계된 정보만 출력할 수 있다. 이러한 특징에 따라 각 노드는 자신과 관계된 계산에만 집중하면 된다.</p><p><img data-src="https://t1.daumcdn.net/cfile/tistory/991C9E495B98F60F1D" data-proofer-ignore></p><center><small>▲ 국소적 계산의 예</small></center><h3 id="513-왜-계산-그래프로-푸는가"><span class="mr-2">5.1.3 왜 계산 그래프로 푸는가?</span><a href="#513-왜-계산-그래프로-푸는가" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>계산 그래프의 이점</p><ul><li>국소적 계산으로 복잡한 문제를 단순화할 수 있다.<li>역전파를 통해 (다수의) 미분을 효율적으로 계산할 수 있다.</ul><p><img data-src="https://t1.daumcdn.net/cfile/tistory/997E914D5B98F62826" data-proofer-ignore></p><center><small>▲ 역전파를 통한 미분</small></center><h2 id="52-연쇄법칙chain-rule"><span class="mr-2">5.2 연쇄법칙(chain rule)</span><a href="#52-연쇄법칙chain-rule" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="521-계산-그래프의-역전파"><span class="mr-2">5.2.1 계산 그래프의 역전파</span><a href="#521-계산-그래프의-역전파" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><img data-src="https://t1.daumcdn.net/cfile/tistory/999FD3425B98F63F1A" data-proofer-ignore></p><p>국소적 미분은 상류에서 전달된 값과 곱해져서 앞쪽 노드로 전달된다.</p><h3 id="522-연쇄법칙이란"><span class="mr-2">5.2.2 연쇄법칙이란?</span><a href="#522-연쇄법칙이란" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>연쇄법칙은 합성 함수의 미분이 각 구성 함수의 미분의 곱으로 나타낸다는 성질을 이용한다.</p><p>예를 들어, $z = (x + y)^2$가 있을때 $x$에 대한 $z$의 미분은 다음과 같이 나타낼 수 있다.</p>\[\frac {\partial z} {\partial x} = \frac {\partial z} {\partial t} \frac {\partial t} {\partial x}\] \[\frac {\partial z} {\partial t} = 2t\] \[\frac {\partial t} {\partial x} = 1\] \[\frac {\partial z} {\partial x} = \frac {\partial z} {\partial t} \frac {\partial t} {\partial x} = 2t \cdot 1 = 2(x + y)\]<h3 id="523-연쇄법칙과-계산-그래프"><span class="mr-2">5.2.3 연쇄법칙과 계산 그래프</span><a href="#523-연쇄법칙과-계산-그래프" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><img data-src="https://t1.daumcdn.net/cfile/tistory/997387465B98F65D13" data-proofer-ignore></p><h2 id="53-역전파"><span class="mr-2">5.3 역전파</span><a href="#53-역전파" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="531-덧셈-노드의-역전파"><span class="mr-2">5.3.1 덧셈 노드의 역전파</span><a href="#531-덧셈-노드의-역전파" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>덧셈 노드의 역전파는 입력된 값을 그대로 다음 노드로 보낸다.</p><p><img data-src="https://t1.daumcdn.net/cfile/tistory/99FB57455B98F67407" data-proofer-ignore></p><h3 id="532-곱셈-노드의-역전파"><span class="mr-2">5.3.2 곱셈 노드의 역전파</span><a href="#532-곱셈-노드의-역전파" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>곱셈 노드의 역전파는 순전파 때의 입력 신호들을 서로 바꾼 값을 곱해서 하류로 보낸다. 그래서 곱셈 노드를 구현할 때는 순전파의 입력 신호를 변수에 저장한다.</p><p><img data-src="https://t1.daumcdn.net/cfile/tistory/99E3EF435B98F69309" data-proofer-ignore></p><h3 id="533-사과-쇼핑의-예"><span class="mr-2">5.3.3 사과 쇼핑의 예</span><a href="#533-사과-쇼핑의-예" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><img data-src="https://t1.daumcdn.net/cfile/tistory/99AACA445B98F6A61E" data-proofer-ignore></p><center><small>▲ 사과 쇼핑의 역전파 예</small></center><p><img data-src="https://t1.daumcdn.net/cfile/tistory/99499E4E5B98F6C10E" data-proofer-ignore></p><center><small>▲ 사과와 귤 쇼핑의 역전파 예</small></center><h2 id="54-단순한-계층-구현하기"><span class="mr-2">5.4 단순한 계층 구현하기</span><a href="#54-단순한-계층-구현하기" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="541-곱셈-계층"><span class="mr-2">5.4.1 곱셈 계층</span><a href="#541-곱셈-계층" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">MulLayer</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="bp">None</span>
        
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span>
        
        <span class="k">return</span> <span class="n">out</span>
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dout</span><span class="p">):</span>
        <span class="n">dx</span> <span class="o">=</span> <span class="n">dout</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">y</span>
        <span class="n">dy</span> <span class="o">=</span> <span class="n">dout</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">x</span>
        
        <span class="k">return</span> <span class="n">dx</span><span class="p">,</span> <span class="n">dy</span>
</pre></table></code></div></div><ul><li>사과 쇼핑 구현</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="n">apple</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">apple_num</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">tax</span> <span class="o">=</span> <span class="mf">1.1</span>

<span class="c1"># 계층들
</span><span class="n">mul_apple_layer</span> <span class="o">=</span> <span class="n">MulLayer</span><span class="p">()</span>
<span class="n">mul_tax_layer</span> <span class="o">=</span> <span class="n">MulLayer</span><span class="p">()</span>

<span class="c1"># 순전파
</span><span class="n">apple_price</span> <span class="o">=</span> <span class="n">mul_apple_layer</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">apple</span><span class="p">,</span> <span class="n">apple_num</span><span class="p">)</span>
<span class="n">price</span> <span class="o">=</span> <span class="n">mul_tax_layer</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">apple_price</span><span class="p">,</span> <span class="n">tax</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">price</span><span class="p">)</span> <span class="c1"># 다들 오차 나는지?
</span></pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>220.00000000000003
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="c1"># 역전파
</span><span class="n">dprice</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">dapple_price</span><span class="p">,</span> <span class="n">dtax</span> <span class="o">=</span> <span class="n">mul_tax_layer</span><span class="p">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dprice</span><span class="p">)</span>
<span class="n">dapple</span><span class="p">,</span> <span class="n">dapple_num</span> <span class="o">=</span> <span class="n">mul_apple_layer</span><span class="p">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dapple_price</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">dapple</span><span class="p">,</span> <span class="n">dapple_num</span><span class="p">,</span> <span class="n">dtax</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>2.2 110.00000000000001 200
</pre></table></code></div></div><h3 id="542-덧셈-계층"><span class="mr-2">5.4.2 덧셈 계층</span><a href="#542-덧셈-계층" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">AddLayer</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>
    
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
        <span class="k">return</span> <span class="n">out</span>
    
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dout</span><span class="p">):</span>
        <span class="n">dx</span> <span class="o">=</span> <span class="n">dout</span> <span class="o">*</span> <span class="mi">1</span>
        <span class="n">dy</span> <span class="o">=</span> <span class="n">dout</span> <span class="o">*</span> <span class="mi">1</span>
        
        <span class="k">return</span> <span class="n">dx</span><span class="p">,</span> <span class="n">dy</span>
</pre></table></code></div></div><p>덧셈 계층은 그저 상류에서 내려온 미분을 하류로 흘러보내기만 하면 되기 때문에 따로 초기화할 필요가 없다.</p><ul><li>사과 2개와 귤 3개를 사는 상황</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre><td class="rouge-code"><pre><span class="n">apple_num</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">apple</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">mandarin_num</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">mandarin</span> <span class="o">=</span> <span class="mi">150</span>
<span class="n">tax</span> <span class="o">=</span> <span class="mf">1.1</span>

<span class="n">mul_apple_layer</span> <span class="o">=</span> <span class="n">MulLayer</span><span class="p">()</span>
<span class="n">mul_mandarin_layer</span> <span class="o">=</span> <span class="n">MulLayer</span><span class="p">()</span>
<span class="n">add_fruit_layer</span> <span class="o">=</span> <span class="n">AddLayer</span><span class="p">()</span>
<span class="n">mul_tax_layer</span> <span class="o">=</span> <span class="n">MulLayer</span><span class="p">()</span>

<span class="n">apple_price</span> <span class="o">=</span> <span class="n">mul_apple_layer</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">apple</span><span class="p">,</span> <span class="n">apple_num</span><span class="p">)</span>
<span class="n">mandarin_price</span> <span class="o">=</span> <span class="n">mul_mandarin_layer</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">mandarin</span><span class="p">,</span> <span class="n">mandarin_num</span><span class="p">)</span>
<span class="n">fruit_price</span> <span class="o">=</span> <span class="n">add_fruit_layer</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">apple_price</span><span class="p">,</span> <span class="n">mandarin_price</span><span class="p">)</span>
<span class="n">total_price</span> <span class="o">=</span> <span class="n">mul_tax_layer</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">fruit_price</span><span class="p">,</span> <span class="n">tax</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">total_price</span><span class="p">)</span>

<span class="n">dtotal_price</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">dfruit_price</span><span class="p">,</span> <span class="n">dtax</span> <span class="o">=</span> <span class="n">mul_tax_layer</span><span class="p">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dprice</span><span class="p">)</span>
<span class="n">dapple_price</span><span class="p">,</span> <span class="n">dmandarin_price</span> <span class="o">=</span> <span class="n">add_fruit_layer</span><span class="p">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dfruit_price</span><span class="p">)</span>
<span class="n">dapple</span><span class="p">,</span> <span class="n">dapple_num</span> <span class="o">=</span> <span class="n">mul_apple_layer</span><span class="p">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dapple_price</span><span class="p">)</span>
<span class="n">dmandarin</span><span class="p">,</span> <span class="n">dmandarin_num</span> <span class="o">=</span> <span class="n">mul_mandarin_layer</span><span class="p">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dmandarin_price</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">dapple</span><span class="p">,</span> <span class="n">dapple_num</span><span class="p">,</span> <span class="n">dmandarin</span><span class="p">,</span> <span class="n">dmandarin_num</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>715.0000000000001
2.2 110.00000000000001 3.3000000000000003 165.0
</pre></table></code></div></div><h2 id="55-활성화-함수-계층-구현하기"><span class="mr-2">5.5 활성화 함수 계층 구현하기</span><a href="#55-활성화-함수-계층-구현하기" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="551-relu-계층"><span class="mr-2">5.5.1 ReLU 계층</span><a href="#551-relu-계층" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>ReLU 수식</ul>\[y = \begin{cases} x \ (x &gt; 0) \\ 0 \ (x \leq 0) \end{cases}\]<ul><li>ReLU 미분</ul>\[\frac {\partial y}{\partial x} = \begin{cases} 1 \ (x &gt; 0) \\ 0 \ (x \leq 0) \end{cases}\]<p><img data-src="https://t1.daumcdn.net/cfile/tistory/99E517485B98F6E504" data-proofer-ignore></p><center><small>▲ ReLU 계산 그래프</small></center><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">Relu</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">,</span><span class="n">mask</span> <span class="o">=</span> <span class="bp">None</span>    <span class="c1"># 입력 원소가 0 이하인 인덱스는 True, 0보다 큰 경우 False 유지
</span>        
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">out</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">return</span> <span class="mi">0</span>
    
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dout</span><span class="p">):</span>
        <span class="n">dout</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">dx</span> <span class="o">=</span> <span class="n">dout</span>
        
        <span class="k">return</span> <span class="n">dx</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]])</span>
<span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>[[ 1.  -0.5]
 [-2.   3. ]]
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>[[False  True]
 [ True False]]
</pre></table></code></div></div><p>mask 인스턴스 변수를 써서 mask의 원소가 True인 곳은 상류에서 전파된 미분값을 0으로 바꾼다.</p><h3 id="552-sigmoid-계층"><span class="mr-2">5.5.2 Sigmoid 계층</span><a href="#552-sigmoid-계층" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>시그모이드 수식</ul>\[y = \frac 1 {1+exp(-x)}\]<ul><li>’/’ 노드, $y = \frac 1 x$ 미분</ul>\[\begin{align} \frac {\partial y} {\partial x} &amp; = -\frac 1 {x^2} \\ &amp; = -y^2 \\ \end{align}\]<ul><li>exp 노드 미분</ul>\[\frac {\partial y} {\partial x} = exp(x)\]<p><img data-src="https://t1.daumcdn.net/cfile/tistory/999E3B4B5B98F72021" data-proofer-ignore></p><center><small>▲ 시그모이드 순전파/역전파</small></center><ul><li>sigmoid 미분</ul>\[\begin{align} \frac {\partial y} {\partial x} &amp; = y^2exp(-x) \\ &amp; = \frac 1 {(1 + exp(-x))^2} exp(-x) \\ &amp; = \frac 1 {1 + exp(-x)} \frac {exp(-x)} {1+exp(-x)} \\ &amp; = y(1-y) \end{align}\]<p>시그모이드 계층의 역전파는 순전파의 출력만으로 계산할 수 있다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">Sigmoid</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">out</span> <span class="o">=</span> <span class="bp">None</span>
    
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">out</span>
        
        <span class="k">return</span> <span class="n">out</span>
    
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dout</span><span class="p">):</span>
        <span class="n">dx</span> <span class="o">=</span> <span class="n">dout</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">out</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">out</span>
        
        <span class="k">return</span> <span class="n">dx</span>
</pre></table></code></div></div><p>구현에서 순전파의 출력을 out 인스턴스 변수에 저장해 놓고 역전파 계산할 때 사용한다.</p><h2 id="56-affinesoftmax-계층-구현하기"><span class="mr-2">5.6 Affine/Softmax 계층 구현하기</span><a href="#56-affinesoftmax-계층-구현하기" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="561-affine-계층"><span class="mr-2">5.6.1 Affine 계층</span><a href="#561-affine-계층" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>행렬의 곱을 기하학에서는 <strong>어파인 변환(affine transformation)</strong>이라고 한다.</p>\[\frac {\partial L} {\partial X} = \frac {\partial L} {\partial Y} \cdot W^T\] \[\frac {\partial L} {\partial W} = X^T \cdot \frac {\partial L} {\partial Y}\]<p><img data-src="https://t1.daumcdn.net/cfile/tistory/994002375B98F73E05" data-proofer-ignore></p><p>계산 그래프에서 각 원소의 형상에 주의해야 한다.</p><h3 id="562-배치용-affine-계층"><span class="mr-2">5.6.2 배치용 Affine 계층</span><a href="#562-배치용-affine-계층" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><img data-src="https://t1.daumcdn.net/cfile/tistory/994510365B98F75122" data-proofer-ignore></p><p>편향의 경우에는 순전파에서 각각의 데이터에 더해진다. 그래서 역전파 때는 편향의 원소에 역전파 값이 편향에 모여야 한다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">Affine</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">W</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dW</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">db</span> <span class="o">=</span> <span class="bp">None</span>
        
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">b</span>
        
        <span class="k">return</span> <span class="n">out</span>
    
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dout</span><span class="p">):</span>
        <span class="n">dx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dout</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">W</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dW</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dout</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">db</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dout</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">dx</span>
</pre></table></code></div></div><h3 id="563-softmax-with-loss-계층"><span class="mr-2">5.6.3 Softmax-with-Loss 계층</span><a href="#563-softmax-with-loss-계층" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Softmax 계층은 출력의 합이 1이 되도록 정규화하여 출력한다.</p><p><img data-src="https://t1.daumcdn.net/cfile/tistory/995A16395B98F76820" data-proofer-ignore></p><p><img data-src="https://t1.daumcdn.net/cfile/tistory/99EBF5395B98F7792B" data-proofer-ignore></p><center><small>▲ Softmax-with-Loss 계층의 계산 그래프</small></center><p><img data-src="https://camo.qiitausercontent.com/c879a9a466f923c0978973590908d2b1c0725592/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f3139373530382f66353935633337652d323562312d383666392d356438632d3937343532343461626633372e706e67" width="450" data-proofer-ignore></p><center><small>▲ Softmax-with-Loss 계층 계산 그래프 간소화</small></center><p>Softmax 계층의 역전파 결과에서 중요한 점은 Softmax 계층의 출력과 정답 레이블의 차이로, 신경망의 현재 출력과 정답 레이블의 오차를 그래로 드러낸다는 것이다.</p><p>참고로 항등 함수의 손실 함수로 평균 제곱 오차를 사용하는데 이 때의 역전파 값도 위와 동일하다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="c1"># 소프트맥스 오버플로 개선 버전
</span><span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">exp_a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">a</span> <span class="o">-</span> <span class="n">c</span><span class="p">)</span>
    <span class="n">sum_exp_a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">exp_a</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">exp_a</span> <span class="o">/</span> <span class="n">sum_exp_a</span>
    
    <span class="k">return</span> <span class="n">y</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="c1"># 데이터가 1개나 그 이상의 배치로 주어지는 경우
</span><span class="k">def</span> <span class="nf">cross_entropy_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="c1"># y가 1차원, 즉 하나의 데이터일 경우 shape을 바꿔준다.
</span>    <span class="k">if</span> <span class="n">y</span><span class="p">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">t</span><span class="p">.</span><span class="n">size</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="p">.</span><span class="n">size</span><span class="p">)</span>
        
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">t</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="mf">1e-7</span><span class="p">))</span> <span class="o">/</span> <span class="n">batch_size</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">SoftmaxWithLoss</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">None</span>   <span class="c1"># 손실
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="bp">None</span>      <span class="c1"># softmax 출력
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">t</span> <span class="o">=</span> <span class="bp">None</span>      <span class="c1"># 정답 레이블(원-핫 벡터)
</span>        
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">t</span> <span class="o">=</span> <span class="n">t</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">cross_entropy_error</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">t</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">loss</span>
    
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dout</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">y</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span>
        
        <span class="k">return</span> <span class="n">dx</span>
</pre></table></code></div></div><h2 id="57-오차역전파법-구현하기"><span class="mr-2">5.7 오차역전파법 구현하기</span><a href="#57-오차역전파법-구현하기" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="571-신경망-학습의-전체-그림-생략"><span class="mr-2">5.7.1 신경망 학습의 전체 그림 (생략)</span><a href="#571-신경망-학습의-전체-그림-생략" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><h3 id="572-오차역전파법을-적용한-신경망-구현하기"><span class="mr-2">5.7.2 오차역전파법을 적용한 신경망 구현하기</span><a href="#572-오차역전파법을-적용한-신경망-구현하기" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">sys</span><span class="p">,</span> <span class="n">os</span>
<span class="n">sys</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">pardir</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">common.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">common.gradient</span> <span class="kn">import</span> <span class="n">numerical_gradient</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">TwoLayerNet</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">weight_init_std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="c1"># 가중치 초기화
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'W1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">weight_init_std</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'W2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">weight_init_std</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">output_size</span><span class="p">)</span>
        
        <span class="c1"># 계층 생성
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="s">'Affine1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">Affine</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">"W1"</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b1'</span><span class="p">])</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="s">'Relu1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">Relu</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="s">'Affine2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">Affine</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'W2'</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b2'</span><span class="p">])</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">lastLayer</span> <span class="o">=</span> <span class="n">SoftmaxWithLoss</span><span class="p">()</span>
        
    
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            
        <span class="k">return</span> <span class="n">x</span>
    
    
    <span class="c1"># x: 입력 데이터, t: 정답 레이블
</span>    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">lastLayer</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    
    
    <span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">t</span><span class="p">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span> <span class="p">:</span> 
            <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        
        <span class="k">return</span> <span class="n">accuracy</span>
    
    
    <span class="c1"># x: 입력 데이터, t: 정답 레이블
</span>    <span class="k">def</span> <span class="nf">numerical_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="n">loss_W</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">W</span><span class="p">:</span> <span class="bp">self</span><span class="p">.</span><span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        
        <span class="n">grads</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'W1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">loss_W</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'W1'</span><span class="p">])</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'b1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">loss_W</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b1'</span><span class="p">])</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'W2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">loss_W</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'W2'</span><span class="p">])</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'b2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">loss_W</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b2'</span><span class="p">])</span>
        
        <span class="k">return</span> <span class="n">grads</span>
    
    
    <span class="k">def</span> <span class="nf">gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="c1"># 순전파
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        
        <span class="c1"># 역전파
</span>        <span class="n">dout</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">dout</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lastLayer</span><span class="p">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dout</span><span class="p">)</span>
        
        <span class="n">layers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">values</span><span class="p">())</span>
        <span class="n">layers</span><span class="p">.</span><span class="n">reverse</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">:</span>
            <span class="n">dout</span> <span class="o">=</span> <span class="n">layer</span><span class="p">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dout</span><span class="p">)</span>
            
        <span class="c1"># 결과 저장
</span>        <span class="n">grads</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'W1'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="s">'Affine1'</span><span class="p">].</span><span class="n">dW</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'b1'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="s">'Affine1'</span><span class="p">].</span><span class="n">db</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'W2'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="s">'Affine2'</span><span class="p">].</span><span class="n">dW</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'b2'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="s">'Affine2'</span><span class="p">].</span><span class="n">db</span>
        
        <span class="k">return</span> <span class="n">grads</span>
</pre></table></code></div></div><h3 id="573-오차역전파법으로-구한-기울기-검증하기"><span class="mr-2">5.7.3 오차역전파법으로 구한 기울기 검증하기</span><a href="#573-오차역전파법으로-구한-기울기-검증하기" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>기울기 구하는 방법</p><ul><li>수치 미분: 구현은 간단하지만 느리다<li>해석적 방법: 오차역전파법 이용해서 매개변수 많아도 빠르게 계산 가능</ul><p>실제 학습을 할 땐 계산이 빠른 오차역전파법을 이용하고 수치 미분은 오차역전파법을 정확하게 구현했는지 확인하는 용도로 사용한다. 두 방식으로 기울기가 일치하는 것을 확인하는 작업을 <strong>기울기 확인(gradient check)</strong>라고 한다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">sys</span><span class="p">,</span> <span class="n">os</span>
<span class="n">sys</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">pardir</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">dataset.mnist</span> <span class="kn">import</span> <span class="n">load_mnist</span>
<span class="kn">from</span> <span class="nn">two_layer_net</span> <span class="kn">import</span> <span class="n">TwoLayerNet</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre><td class="rouge-code"><pre><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">one_hot_label</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">TwoLayerNet</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">x_batch</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
<span class="n">t_batch</span> <span class="o">=</span> <span class="n">t_train</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>

<span class="n">grad_numerical</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><span class="n">numerical_gradient</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">)</span>
<span class="n">grad_backprop</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">)</span>

<span class="c1"># 가 가중치의 차이의 절댓값을 구한 후, 그 절댓값들의 평균을 낸다.
</span><span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">grad_numerical</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">diff</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">average</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">grad_backprop</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">-</span> <span class="n">grad_numerical</span><span class="p">[</span><span class="n">key</span><span class="p">]))</span>
    <span class="k">print</span><span class="p">(</span><span class="n">key</span> <span class="o">+</span> <span class="s">": "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">diff</span><span class="p">))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>W1: 2.0655630540316686e-10
b1: 1.1163263739284333e-09
W2: 7.232095981457576e-08
b2: 1.4492399771914855e-07
</pre></table></code></div></div><h3 id="574-오차역전파법을-사용한-학습-구현하기"><span class="mr-2">5.7.4 오차역전파법을 사용한 학습 구현하기</span><a href="#574-오차역전파법을-사용한-학습-구현하기" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">sys</span><span class="p">,</span> <span class="n">os</span>
<span class="n">sys</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">pardir</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">dataset.mnist</span> <span class="kn">import</span> <span class="n">load_mnist</span>
<span class="kn">from</span> <span class="nn">two_layer_net</span> <span class="kn">import</span> <span class="n">TwoLayerNet</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
</pre><td class="rouge-code"><pre><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">one_hot_label</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">TwoLayerNet</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">iters_num</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">train_loss_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_acc_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_acc_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">iter_per_epoch</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">train_size</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iters_num</span><span class="p">):</span>
    <span class="n">batch_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">x_batch</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>
    <span class="n">t_batch</span> <span class="o">=</span> <span class="n">t_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>
    
    <span class="c1"># 오차역전파법으로 기울기를 구한다.
</span>    <span class="n">grad</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">)</span>
    
    <span class="c1"># 갱신
</span>    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">(</span><span class="s">'W1'</span><span class="p">,</span> <span class="s">'b1'</span><span class="p">,</span> <span class="s">'W2'</span><span class="p">,</span> <span class="s">'b2'</span><span class="p">):</span>
        <span class="n">network</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        
    <span class="n">loss</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><span class="n">loss</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">)</span>
    <span class="n">train_loss_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">iter_per_epoch</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">train_acc</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">)</span>
        <span class="n">test_acc</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span>
        <span class="n">train_acc_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_acc</span><span class="p">)</span>
        <span class="n">test_acc_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_acc</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">train_acc</span><span class="p">,</span> <span class="n">test_acc</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre>0.11236666666666667 0.1135
0.7885 0.7957
0.8772 0.8808
0.8986666666666666 0.9036
0.9084666666666666 0.9127
0.9139166666666667 0.9173
0.9194333333333333 0.9213
0.9230166666666667 0.9252
0.9273333333333333 0.9294
0.9311333333333334 0.9312
0.9345166666666667 0.9336
0.9368833333333333 0.9372
0.9398333333333333 0.9386
0.94185 0.9404
0.9450833333333334 0.9424
0.9458666666666666 0.944
0.9469 0.9467
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>
</pre></table></code></div></div></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/ml/'>ML</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/deep-learning/" class="post-tag no-text-decoration" >Deep_learning</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"></div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0+%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94+%EB%94%A5%EB%9F%AC%EB%8B%9D+Chapter05+-+Yh%27s+blog&url=https%3A%2F%2Fleeje008.github.io%2Fposts%2F%25EB%25B0%2591%25EB%25B0%2594%25EB%258B%25A5%25EB%25B6%2580%25ED%2584%25B0-%25EC%258B%259C%25EC%259E%2591%25ED%2595%2598%25EB%258A%2594-%25EB%2594%25A5%25EB%259F%25AC%25EB%258B%259D-Chapter05%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0+%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94+%EB%94%A5%EB%9F%AC%EB%8B%9D+Chapter05+-+Yh%27s+blog&u=https%3A%2F%2Fleeje008.github.io%2Fposts%2F%25EB%25B0%2591%25EB%25B0%2594%25EB%258B%25A5%25EB%25B6%2580%25ED%2584%25B0-%25EC%258B%259C%25EC%259E%2591%25ED%2595%2598%25EB%258A%2594-%25EB%2594%25A5%25EB%259F%25AC%25EB%258B%259D-Chapter05%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fleeje008.github.io%2Fposts%2F%25EB%25B0%2591%25EB%25B0%2594%25EB%258B%25A5%25EB%25B6%2580%25ED%2584%25B0-%25EC%258B%259C%25EC%259E%2591%25ED%2595%2598%25EB%258A%2594-%25EB%2594%25A5%25EB%259F%25AC%25EB%258B%259D-Chapter05%2F&text=%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0+%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94+%EB%94%A5%EB%9F%AC%EB%8B%9D+Chapter05+-+Yh%27s+blog" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div><script src="https://utteranc.es/client.js" repo="leeje008/leeje008.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter02/">밑바닥부터 시작하는 딥러닝 Chapter02</a><li><a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter03/">밑바닥부터 시작하는 딥러닝 Chapter03</a><li><a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter04/">밑바닥부터 시작하는 딥러닝 Chapter04</a><li><a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter06/">밑바닥부터 시작하는 딥러닝 Chapter06</a><li><a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter07/">밑바닥부터 시작하는 딥러닝 Chapter07</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/deep-learning/">Deep_learning</a> <a class="post-tag" href="/tags/subject-project/">subject_project</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4"><div id="related-posts" class="mb-2 mb-sm-4"><h3 class="pt-2 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter02/"><div class="card-body"> <em class="small" data-ts="1636815600" data-df="ll" > Nov 14, 2021 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>밑바닥부터 시작하는 딥러닝 Chapter02</h3><div class="text-muted small"><p> 퍼셉트론 퍼셉트론 perceptron 알고리즘. 프랑크 로젠블라트가 1957년 고안한 알고리즘이고, 신경망(딥러닝)의 기원이 되는 알고리즘이다. 퍼셉트론은 딥러닝으로 나아가는 데 중요한 아이디어를 준다. 퍼셉트론 다수의 신호를 입력으로 하나의 신호를 출력한다. 신호 : 전류나 강물처럼 흐름 1을 신호가 흐른다. 0을 신호가 흐...</p></div></div></a></div><div class="card"> <a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter03/"><div class="card-body"> <em class="small" data-ts="1636815600" data-df="ll" > Nov 14, 2021 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>밑바닥부터 시작하는 딥러닝 Chapter03</h3><div class="text-muted small"><p> 신경망 가중치 매개변수의 적절한 값을 데이터에서 자동으로 학습하는 능력이 신경망의 중요한 성질이다. 신경망의 개요, 신경망이 입력 데이터가 무엇인지 식별하는 처리 과정을 알아보자. 퍼셉트론에서 신경망으로 퍼셉트론과 다른 점으로 신경망 구조를 살펴보자. 신경망의 예 신경망 그림을 참고한다. 가장 왼쪽 줄을 입력층, 가장 오른쪽 줄을 출력층, ...</p></div></div></a></div><div class="card"> <a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter04/"><div class="card-body"> <em class="small" data-ts="1637334000" data-df="ll" > Nov 20, 2021 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>밑바닥부터 시작하는 딥러닝 Chapter04</h3><div class="text-muted small"><p> CH04 신경망 학습 학습이란? 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것을 의미함 4.1 데이터로부터 학습한다 =&amp;gt; 신경망의 주요한 특징 中 하나는 데이터를 통해 가중치가 결정된다! 퍼셉트론 수렴 정리 내용: 선형 분리 문제는 유한번의 학습을 통해 풀 수 있다! 정리 $ X^+,X^- 가\ 선형\ 분리\ 가능...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter04/" class="btn btn-outline-primary" prompt="Older"><p>밑바닥부터 시작하는 딥러닝 Chapter04</p></a> <a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter06/" class="btn btn-outline-primary" prompt="Newer"><p>밑바닥부터 시작하는 딥러닝 Chapter06</p></a></div></div></div><footer class="row pl-3 pr-3"><div class="col-12 d-flex justify-content-between align-items-center text-muted pl-0 pr-0"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://github.com/leeje008">Koyounghun</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">All rights reserved</span></p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/deep-learning/">Deep_learning</a> <a class="post-tag" href="/tags/subject-project/">subject_project</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/ko.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script>
