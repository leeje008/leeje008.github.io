<!DOCTYPE html><html lang="ko" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="밑바닥부터 시작하는 딥러닝 Chapter06" /><meta property="og:locale" content="ko" /><meta name="description" content="Chapter 6 학습 관련 기술들" /><meta property="og:description" content="Chapter 6 학습 관련 기술들" /><link rel="canonical" href="https://leeje008.github.io/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter06/" /><meta property="og:url" content="https://leeje008.github.io/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter06/" /><meta property="og:site_name" content="Yh’s blog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-11-25T00:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="밑바닥부터 시작하는 딥러닝 Chapter06" /><meta name="twitter:site" content="@twitter_username" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-09-05T17:02:11+09:00","datePublished":"2021-11-25T00:00:00+09:00","description":"Chapter 6 학습 관련 기술들","headline":"밑바닥부터 시작하는 딥러닝 Chapter06","mainEntityOfPage":{"@type":"WebPage","@id":"https://leeje008.github.io/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter06/"},"url":"https://leeje008.github.io/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter06/"}</script><title>밑바닥부터 시작하는 딥러닝 Chapter06 | Yh's blog</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Yh's blog"><meta name="application-name" content="Yh's blog"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="/assets/img/me3.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Yh's blog</a></div><div class="site-subtitle font-italic">Final success will be made repeated attempts</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/leeje008" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['leeje008','naver.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="https://www.facebook.com/profile.php?id=100006983951106" aria-label="facebook" > <i class="fab fa-facebook"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>밑바닥부터 시작하는 딥러닝 Chapter06</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4 pb-5"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>밑바닥부터 시작하는 딥러닝 Chapter06</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1637766000" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Nov 25, 2021 </em> </span> <span> Updated <em class="" data-ts="1662364931" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Sep 5, 2022 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="https://github.com/leeje008">Koyounghun</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="6773 words"> <em>37 min</em> read</span></div></div></div><div class="post-content"><h1 id="chapter-6-학습-관련-기술들">Chapter 6 학습 관련 기술들</h1><p>딥러닝 학습 효율, 정확도 개선 방법</p><ul><li>가중치 매개변수 최적값 탐색하는 최적화 방법<li>가중치 매개변수 초깃값<li>하이퍼파라미터 설정 방법<li>오버피팅 대응책<ul><li>가중치 감소<li>드롭아웃</ul><li>배치 정규화</ul><h2 id="61-매개변수-갱신"><span class="mr-2">6.1 매개변수 갱신</span><a href="#61-매개변수-갱신" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>신경망 학습의 목표는 매개변수의 최적값을 찾는 <strong>최적화(optimization)</strong>이다. 여태까지 사용한 최적화 방법으로 미분을 이용했는데 이 방법을 <strong>확률적 경사 하강법(SGD)</strong>라고 한다.</p><h3 id="611-모험가-이야기-생략"><span class="mr-2">6.1.1 모험가 이야기 (생략)</span><a href="#611-모험가-이야기-생략" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><h3 id="612-확률적-경사-하강법sgd"><span class="mr-2">6.1.2 확률적 경사 하강법(SGD)</span><a href="#612-확률적-경사-하강법sgd" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>SGD 수식</ul>\[W \leftarrow W - \eta \frac {\partial L} {\partial W}\]<div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">SGD</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
        
    
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">params</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">*</span> <span class="n">grads</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
</pre></table></code></div></div><p>다음은 SGD 클래스를 사용하는 의사코드 예시이다.</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre>network = TwoLayerNet(...)
optimizer = SGD()

for i in range(10000):
    ...
    x_batch, t_batch = get_mini_batch(...)
    grads = network.gradient(x_batch, t_batch)
    params = network.params
    optimizer.update(params, grads)
    ...
</pre></table></code></div></div><p>매개 변수 갱신은 optimizer가 책임을 지고 optimizer에 매개변수와 기울기 정보만 넘겨주면 된다. 여러 최적화 관련 클래스를 만들어 모듈화하면 다양한 방법으로 쉽게 최적화할 수 있다.</p><h3 id="613-sgd의-단점"><span class="mr-2">6.1.3 SGD의 단점</span><a href="#613-sgd의-단점" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>예시 함수</ul>\[f(x, y) = \frac 1 {20} x^2 + y^2\]<p><img data-src="https://mblogthumb-phinf.pstatic.net/MjAxNzA3MjdfMjU3/MDAxNTAxMTIxODU0MTYx.RZxiBW4kDiXReqK1UDxfBAffbM-pWJQwEI82m-evhucg.N_UhoBOXaCVYUPsP4wuoi4UUL1qQ_5iNEB000_QP1S4g.PNG.cjswo9207/fig_6-1.png?type=w2" data-proofer-ignore></p><center><small>▲ 그래프(왼쪽), 등고선(오른쪽)</small></center><p><img data-src="https://mblogthumb-phinf.pstatic.net/MjAxNzA3MjdfMTMx/MDAxNTAxMTIxOTIwOTE4.b5qnZS_a5u0UOQV16EQzWZpGXpmAkjKeqNVE8COqaNQg.sO1Li2aqIyVhpv3h1NfwLCuyqUfw9G1GZR-Nbsy0trgg.PNG.cjswo9207/fig_6-2.png?type=w2" data-proofer-ignore></p><center><small>▲ 기울기</small></center><p>최솟값이 되는 위치는 $(x, y) = (0, 0)$이지만 대부분의 기울기는 $(0, 0)$을 가리키지 않는다.</p><p><img data-src="https://mblogthumb-phinf.pstatic.net/MjAxNzA3MjdfMTU0/MDAxNTAxMTIyMDAwNTA1.E7zIAUXugKPAA5WiBXpF7HtATQ8nVjfBvJF-LJwqtsIg.52gqDjo2sPPup4Bfz5hOtp_b1svFcFItoYAJreHPp6Ag.PNG.cjswo9207/fig_6-3.png?type=w2" data-proofer-ignore></p><center><small>▲ SGD에 의한 최적화 갱신 경로</small></center><ul><li>비등방성 함수(방향에 따라 기울기가 달라지는 함수)에서 탐색 경로가 비효율적<li>근본 원인은 최솟값과 다른 방향을 가리키는 기울기</ul><h3 id="614-모멘텀momentum"><span class="mr-2">6.1.4 모멘텀(Momentum)</span><a href="#614-모멘텀momentum" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>\(\mathbf{v} \leftarrow \alpha \mathbf{v} - \eta \frac {\partial L} {\partial W}\) \(W \leftarrow W + \mathbf{v}\)</p><ul><li>$\mathbf{v}$: 속도<li>위의 첫번째 식은 기울기 방향으로 힘을 받아 물체가 가속된다는 물리 법칙을 나타낸다.<li>$\alpha\mathbf{v}$: 물체가 아무런 힘을 받지 않을 때 서서히 하강시키는 역할</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">Momentum</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">v</span> <span class="o">=</span> <span class="bp">None</span>
        
    
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">v</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">v</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">params</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
                
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">params</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">momentum</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">lr</span><span class="o">*</span><span class="n">grads</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
</pre></table></code></div></div><p><img data-src="https://mblogthumb-phinf.pstatic.net/MjAxNzA3MjdfMjQ5/MDAxNTAxMTIzNzcxMjY4.pW8LeX0QqcoQMI1qBQmpYf9skv8k0G2SBAqrmk_uP84g.CKPbYA_icOECAZXhBTB_g1qzmDRdtL3vUbEfbU4Y8yMg.PNG.cjswo9207/fig_6-5.png?type=w2" data-proofer-ignore></p><center><small>▲ 모멘텀에 의한 최적화 갱신 경로</small></center><p>Q: 모멘텀 왜 이런 식으로 움직이는지?</p><p>SGD와 비교하면 지그재그가 덜 하다. 이유는 $x$축의 힘은 작지만 방향이 변하지 않아서 일정하게 가속하고 $y$축의 힘은 크지만 위아래로 번갈아 받아서 상충하여 $y$축 방향의 속도는 안정적이지 않기 때문이다.</p><h3 id="615-adagrad"><span class="mr-2">6.1.5 AdaGrad</span><a href="#615-adagrad" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><strong>학습률 감소(learning rate decay)</strong><br /> 학습을 진행하면서 학습률을 점차 줄여나가는 방법</p><p>AdaGrad는 개별 매개 변수에 적응적으로 학습률을 조정하면서 학습을 진행한다.</p>\[\mathbf{h} \leftarrow \mathbf{h} + \frac {\partial L} {\partial \mathbf{W}} \odot \frac {\partial L} {\partial \mathbf{W}}\] \[\mathbf{W} \leftarrow \mathbf{W} - \eta \frac 1 {\sqrt{\mathbf{h}}} \frac {\partial L} {\partial \mathbf{W}}\]<ul><li>$\odot$: 행렬 원소별 곱셈<li>$\mathbf{h}$: 기존 기울기 제곱해서 계속 더해주고 매개변수 갱신할 때 $\frac 1 {\sqrt{\mathbf{h}}}$로 학습률 조정<li>많이 움직인 원소의 학습률이 낮아짐</ul><p>AdaGrad는 과거의 기울기의 제곱을 계속 누적해서 어느 순간 갱신량이 0이 되는 문제가 발생한다. 이를 개선한 기법으로 RMSProp이 있다. RMSProp은 지수이동평균을 이용해서 과거의 기울기를 서서히 잊고 새로운 기울기 정보를 더욱 크게 반영한다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">AdaGrad</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">h</span> <span class="o">=</span> <span class="bp">None</span>
        
    
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">h</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">h</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">parmas</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">h</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
                
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">params</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">h</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="n">grads</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">*</span> <span class="n">grads</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">*</span> <span class="n">gras</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">h</span><span class="p">[</span><span class="n">key</span><span class="p">])</span> <span class="o">+</span> <span class="mf">1e-7</span><span class="p">)</span>
</pre></table></code></div></div><p>1e-7을 더해주는 이유는 0으로 나누는 일을 막기 위함이다. 대분분의 딥러닝 프레임워크에서 이 값도 인수로 설정할 수 있다.</p><p><img data-src="https://mblogthumb-phinf.pstatic.net/MjAxNzA3MjdfNDQg/MDAxNTAxMTI0NTczMDQz.1HzCY4kj0AqKMon65oOJdYfaIxGveuUjawHvH_XOtnkg.0Pf9RCSvNNbZiEqybl7EOt2b49lmHFcWSbFeBpnQG2Yg.PNG.cjswo9207/fig_6-6.png?type=w2" data-proofer-ignore></p><center><small>▲ AdaGrad에 의한 최적화 갱신 경로</small></center><p>$y$축 방향은 기울기가 처음엔 크게 움직이지만, 이에 비례해서 갱신 정도도 빠르게 감소하기 때문에 지그재그 움직임이 줄어든다.</p><h3 id="616-adam"><span class="mr-2">6.1.6 Adam</span><a href="#616-adam" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>모멘텀과 AdaGrad를 융합한 것 같은 방법<li>편향 보정</ul><p><img data-src="https://mblogthumb-phinf.pstatic.net/MjAxNzA3MjdfMTY2/MDAxNTAxMTI0OTE5MzQz.uHy8VlKoQt9RgdMVQW0MZeae_puzDlTicctRfuKwwHIg.fET0kHfJPIXGMn261G-pdMItHWRM_hE6Y9tX2EMSa20g.PNG.cjswo9207/fig_6-7.png?type=w2" data-proofer-ignore></p><center><small>▲ Adam에 의한 최적화 갱신 경로</small></center><p>Adam의 하이퍼파라미터</p><ul><li>학습률 $\alpha$<li>일차 모멘텀용 계수 $\beta_1$: 0.9(기본값)<li>이차 모멘텀용 계수 $\beta_2$: 0.999(기본값)</ul><h3 id="617-어느-갱신-방법을-이용할-것인가"><span class="mr-2">6.1.7 어느 갱신 방법을 이용할 것인가?</span><a href="#617-어느-갱신-방법을-이용할-것인가" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>위의 그래프들을 비교했을 때 AdaGrad가 가장 좋을 것 같지만 문제에 따라 다르다. 상황에 맞게 선택하는 것이 중요하다.</p><h3 id="618-mnist-데이터셋으로-본-갱신-방법-비교"><span class="mr-2">6.1.8 MNIST 데이터셋으로 본 갱신 방법 비교</span><a href="#618-mnist-데이터셋으로-본-갱신-방법-비교" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
</pre><td class="rouge-code"><pre><span class="c1"># coding: utf-8
</span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="n">sys</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">pardir</span><span class="p">)</span>  <span class="c1"># 부모 디렉터리의 파일을 가져올 수 있도록 설정
</span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">dataset.mnist</span> <span class="kn">import</span> <span class="n">load_mnist</span>
<span class="kn">from</span> <span class="nn">common.util</span> <span class="kn">import</span> <span class="n">smooth_curve</span>
<span class="kn">from</span> <span class="nn">common.multi_layer_net</span> <span class="kn">import</span> <span class="n">MultiLayerNet</span>
<span class="kn">from</span> <span class="nn">common.optimizer</span> <span class="kn">import</span> <span class="o">*</span>


<span class="c1"># 0. MNIST 데이터 읽기==========
</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">train_size</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">max_iterations</span> <span class="o">=</span> <span class="mi">2000</span>


<span class="c1"># 1. 실험용 설정==========
</span><span class="n">optimizers</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">optimizers</span><span class="p">[</span><span class="s">'SGD'</span><span class="p">]</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">()</span>
<span class="n">optimizers</span><span class="p">[</span><span class="s">'Momentum'</span><span class="p">]</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">()</span>
<span class="n">optimizers</span><span class="p">[</span><span class="s">'AdaGrad'</span><span class="p">]</span> <span class="o">=</span> <span class="n">AdaGrad</span><span class="p">()</span>
<span class="n">optimizers</span><span class="p">[</span><span class="s">'Adam'</span><span class="p">]</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">()</span>
<span class="c1">#optimizers['RMSprop'] = RMSprop()
</span>
<span class="n">networks</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">train_loss</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">optimizers</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">networks</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">MultiLayerNet</span><span class="p">(</span>
        <span class="n">input_size</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">hidden_size_list</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
        <span class="n">output_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">train_loss</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>    


<span class="c1"># 2. 훈련 시작==========
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iterations</span><span class="p">):</span>
    <span class="n">batch_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">x_batch</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>
    <span class="n">t_batch</span> <span class="o">=</span> <span class="n">t_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>
    
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">optimizers</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">networks</span><span class="p">[</span><span class="n">key</span><span class="p">].</span><span class="n">gradient</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">)</span>
        <span class="n">optimizers</span><span class="p">[</span><span class="n">key</span><span class="p">].</span><span class="n">update</span><span class="p">(</span><span class="n">networks</span><span class="p">[</span><span class="n">key</span><span class="p">].</span><span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">)</span>
    
        <span class="n">loss</span> <span class="o">=</span> <span class="n">networks</span><span class="p">[</span><span class="n">key</span><span class="p">].</span><span class="n">loss</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">)</span>
        <span class="n">train_loss</span><span class="p">[</span><span class="n">key</span><span class="p">].</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span> <span class="s">"==========="</span> <span class="o">+</span> <span class="s">"iteration:"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s">"==========="</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">optimizers</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">networks</span><span class="p">[</span><span class="n">key</span><span class="p">].</span><span class="n">loss</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="n">key</span> <span class="o">+</span> <span class="s">":"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">loss</span><span class="p">))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre>===========iteration:1800===========
SGD:0.2273494384423423
Momentum:0.0831109822073276
AdaGrad:0.030900737592896608
Adam:0.037067473804141174
===========iteration:1900===========
SGD:0.1857942076948705
Momentum:0.06184418686111305
AdaGrad:0.05637063636435206
Adam:0.0883517703401202
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="c1"># 3. 그래프 그리기==========
</span><span class="n">markers</span> <span class="o">=</span> <span class="p">{</span><span class="s">"SGD"</span><span class="p">:</span> <span class="s">"o"</span><span class="p">,</span> <span class="s">"Momentum"</span><span class="p">:</span> <span class="s">"x"</span><span class="p">,</span> <span class="s">"AdaGrad"</span><span class="p">:</span> <span class="s">"s"</span><span class="p">,</span> <span class="s">"Adam"</span><span class="p">:</span> <span class="s">"D"</span><span class="p">}</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">max_iterations</span><span class="p">)</span>
<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">optimizers</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">smooth_curve</span><span class="p">(</span><span class="n">train_loss</span><span class="p">[</span><span class="n">key</span><span class="p">]),</span> <span class="n">marker</span><span class="o">=</span><span class="n">markers</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">markevery</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"iterations"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img data-src="/assets/img/Chapter6/output_25_0.png" alt="png" data-proofer-ignore></p><h2 id="62-가중치의-초깃값"><span class="mr-2">6.2 가중치의 초깃값</span><a href="#62-가중치의-초깃값" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="621-초깃값을-0으로-하면"><span class="mr-2">6.2.1 초깃값을 0으로 하면?</span><a href="#621-초깃값을-0으로-하면" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>가중치 감소(weight decay)</p><ul><li>가중치 매개변수 값이 작아지도록 학습하는 방법<li>오버피팅 억제 효과</ul><p><strong>가중치 초깃값을 0으로(균일한 값으로) 시작하면?</strong></p><ul><li>올바른 학습 X<li>오차역전파법에서 모든 가중치 값이 똑같이 갱신되기 때문에<li><strong>해결: 초깃값을 무작위로 설정</strong></ul><h3 id="622-은닉층의-활성화값-분포"><span class="mr-2">6.2.2 은닉층의 활성화값 분포</span><a href="#622-은닉층의-활성화값-분포" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>시그모이드 함수를 활성화 함수로 사용하는 5층 신경망을 통해 실험</p><ul><li>각 층의 뉴런은 100개<li>입력 데이터 수는 1000개<li>표준편차가 1인 정규분포 이용</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">node_num</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">hidden_layer_size</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">activations</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hidden_layer_size</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">activations</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">node_num</span><span class="p">,</span> <span class="n">node_num</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">activations</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">z</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">activations</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">activations</span><span class="p">),</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="s">"-layer"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="mi">30</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img data-src="/assets/img/Chapter6/output_34_0.png" alt="png" data-proofer-ignore></p><ul><li>활성화 값의 분포가 0, 1에 치우쳐져 있다.<li>시그모이드 함수는 0, 1에 가까워질 수록 미분값이 0에 가까워진다.<li>미분값이 0에 가까워지면 더 이상 갱신이 일어나지 않는 <strong>기울기 소실(gradient vanishing)</strong> 문제가 발생한다.</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">node_num</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">hidden_layer_size</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">activations</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hidden_layer_size</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">activations</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">node_num</span><span class="p">,</span> <span class="n">node_num</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">activations</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">z</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">activations</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">activations</span><span class="p">),</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="s">"-layer"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="mi">30</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img data-src="/assets/img/Chapter6/output_37_0.png" alt="png" data-proofer-ignore></p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">activations</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
</pre><td class="rouge-code"><pre>{0: array([[0.47510529, 0.5337012 , 0.50246425, ..., 0.53564721, 0.51806879,
         0.52973781],
        [0.48389798, 0.49156359, 0.5004307 , ..., 0.47501203, 0.50423051,
         0.481287  ],
        [0.45297996, 0.49237966, 0.47288158, ..., 0.45614095, 0.44685061,
         0.50093314],
        ...,
        [0.48098354, 0.50503036, 0.50289379, ..., 0.48413844, 0.5159619 ,
         0.51706842],
        [0.50609917, 0.54160537, 0.47694298, ..., 0.50507099, 0.50068575,
         0.48808848],
        [0.52785112, 0.50274475, 0.50429485, ..., 0.48173126, 0.52671102,
         0.49431768]]),
 1: array([[0.48001208, 0.47977019, 0.50622738, ..., 0.48648041, 0.52498678,
         0.5052194 ],
        [0.48087855, 0.48119919, 0.50589301, ..., 0.48710548, 0.524929  ,
         0.50659169],
        [0.48089019, 0.47950954, 0.50513487, ..., 0.48614814, 0.52541495,
         0.5052187 ],
        ...,
        [0.48043455, 0.48054057, 0.50529645, ..., 0.48716627, 0.52480393,
         0.50565974],
        [0.48068606, 0.47960207, 0.5055231 , ..., 0.48589233, 0.52555305,
         0.50566242],
        [0.48097261, 0.48197977, 0.50566901, ..., 0.48599371, 0.5252626 ,
         0.50501786]]),
 2: array([[0.50681215, 0.5059925 , 0.47340957, ..., 0.48943754, 0.49200943,
         0.50938571],
        [0.50682023, 0.50598354, 0.47340571, ..., 0.48944364, 0.49201049,
         0.50935569],
        [0.50681171, 0.50596828, 0.4734341 , ..., 0.48948501, 0.49200742,
         0.50937377],
        ...,
        [0.50680604, 0.50599338, 0.47339008, ..., 0.48944666, 0.49202149,
         0.50936353],
        [0.50679272, 0.50598412, 0.47341447, ..., 0.48947331, 0.4920083 ,
         0.50937677],
        [0.50685574, 0.50597987, 0.47342398, ..., 0.48945713, 0.49202442,
         0.50937627]]),
 3: array([[0.50155717, 0.49433578, 0.50044248, ..., 0.51843858, 0.50104222,
         0.50660993],
        [0.50155707, 0.4943363 , 0.50044235, ..., 0.51843929, 0.50104243,
         0.50661035],
        [0.5015564 , 0.49433615, 0.50044264, ..., 0.51843894, 0.50104258,
         0.50661065],
        ...,
        [0.5015568 , 0.49433624, 0.50044235, ..., 0.51843884, 0.50104207,
         0.50660972],
        [0.50155734, 0.49433565, 0.50044284, ..., 0.51843939, 0.50104298,
         0.50661071],
        [0.50155634, 0.4943358 , 0.50044234, ..., 0.51843954, 0.50104276,
         0.50660979]]),
 4: array([[0.49676083, 0.4894059 , 0.50475826, ..., 0.49040016, 0.51208435,
         0.51251658],
        [0.49676083, 0.4894059 , 0.50475824, ..., 0.49040017, 0.51208433,
         0.51251657],
        [0.49676082, 0.4894059 , 0.50475823, ..., 0.49040017, 0.51208434,
         0.51251657],
        ...,
        [0.49676082, 0.4894059 , 0.50475825, ..., 0.49040016, 0.51208435,
         0.51251657],
        [0.49676083, 0.48940588, 0.50475824, ..., 0.49040017, 0.51208433,
         0.51251656],
        [0.49676082, 0.48940592, 0.50475825, ..., 0.49040017, 0.51208435,
         0.51251658]])}
</pre></table></code></div></div><p>표준편차가 0.01인 정규분포의 활성화값 분포</p><ul><li>0.5 근처에 분포<li>기울기 소실 문제는 발생하지 않는다.<li>대부분의 활성화 값이 0.5 근처에 분포해서 뉴런을 여러 개 둔 의미가 상실된다.<li><strong>표현력을 제한한다.</strong></ul><p><strong>Xavier 초깃값</strong></p><ul><li>각 층의 활성화값들을 광범위하게 분포시킬 목적<li>앞 계층의 노드가 $n$개라면 표준편차가 $\frac 1 {\sqrt n}$인 분포 사용<li>앞 층의 노드수가 많을 수록 대상 노드의 초깃값으로 설정하는 가중치가 좁게 퍼짐</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">node_num</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">hidden_layer_size</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">activations</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hidden_layer_size</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">activations</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">node_num</span><span class="p">,</span> <span class="n">node_num</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">node_num</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">activations</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">z</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">activations</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">activations</span><span class="p">),</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="s">"-layer"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="mi">30</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img data-src="/assets/img/Chapter6/output_42_0.png" alt="png" data-proofer-ignore></p><ul><li>앞의 방식들보다 넓게 분포<li>층이 깊어질수록 형태가 다소 일그러짐, 이는 시그모이드 함수가 (0, 0.5)에서 대칭인 S 곡선이기 때문이다. tanh를 사용하면 해결 가능</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">node_num</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">hidden_layer_size</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">activations</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hidden_layer_size</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">activations</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">node_num</span><span class="p">,</span> <span class="n">node_num</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">node_num</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">tanh</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">activations</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">z</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">activations</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">activations</span><span class="p">),</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="s">"-layer"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="mi">30</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img data-src="/assets/img/Chapter6/output_46_0.png" alt="png" data-proofer-ignore></p><p>활성화 함수로 tanh를 사용</p><ul><li>시그모이드를 사용했을 때보다 깔끔한 종 모양<li>Xavier 초깃값은 원점에서 대칭인 함수가 바람직하다.</ul><h3 id="623-relu를-사용할-때의-가중치-초깃값"><span class="mr-2">6.2.3 ReLU를 사용할 때의 가중치 초깃값</span><a href="#623-relu를-사용할-때의-가중치-초깃값" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>RelU에 적합한 초깃값 이용 권장: <strong>He 초깃값</strong><li>앞 계층의 노드가 $n$개일 때, 표준편차가 $\sqrt{\frac 2 n}$인 정규분포 사용<li>ReLU의 반이 0이라서 더 넓게 분포시키기 위해서 2배의 계수가 필요</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">node_num</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">hidden_layer_size</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">activations</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hidden_layer_size</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">activations</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">node_num</span><span class="p">,</span> <span class="n">node_num</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">activations</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">z</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">activations</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">activations</span><span class="p">),</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="s">"-layer"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="mi">30</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img data-src="/assets/img/Chapter6/output_52_0.png" alt="png" data-proofer-ignore></p><p>표준편차가 0.01인 정규분포를 가중치 초깃값으로 사용한 경우</p><ul><li>학습이 거의 이뤄지지 않음</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">node_num</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">hidden_layer_size</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">activations</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hidden_layer_size</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">activations</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">node_num</span><span class="p">,</span> <span class="n">node_num</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">node_num</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">activations</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">z</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">activations</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">activations</span><span class="p">),</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="s">"-layer"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="mi">30</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img data-src="/assets/img/Chapter6/output_55_0.png" alt="png" data-proofer-ignore></p><p>Xavier 초깃값을 사용한 경우</p><ul><li>활성화 값들의 치우침도 커지고, 기울기 소실 문제도 발생</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">node_num</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">hidden_layer_size</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">activations</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hidden_layer_size</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">activations</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">node_num</span><span class="p">,</span> <span class="n">node_num</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span> <span class="o">/</span> <span class="n">node_num</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">activations</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">z</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">activations</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">activations</span><span class="p">),</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="s">"-layer"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="mi">30</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img data-src="/assets/img/Chapter6/output_58_0.png" alt="png" data-proofer-ignore></p><p>He 초깃값을 사용한 경우</p><ul><li>모든 층에서 균일하게 분포</ul><p>결론</p><ul><li>ReLU: He 초깃값<li>S자 활성화 함수: Xavier 초깃값</ul><h3 id="624-mnist-데이터셋으로-본-가중치-초깃값-비교"><span class="mr-2">6.2.4 MNIST 데이터셋으로 본 가중치 초깃값 비교</span><a href="#624-mnist-데이터셋으로-본-가중치-초깃값-비교" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
</pre><td class="rouge-code"><pre><span class="c1"># coding: utf-8
</span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="n">sys</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">pardir</span><span class="p">)</span>  <span class="c1"># 부모 디렉터리의 파일을 가져올 수 있도록 설정
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">dataset.mnist</span> <span class="kn">import</span> <span class="n">load_mnist</span>
<span class="kn">from</span> <span class="nn">common.util</span> <span class="kn">import</span> <span class="n">smooth_curve</span>
<span class="kn">from</span> <span class="nn">common.multi_layer_net</span> <span class="kn">import</span> <span class="n">MultiLayerNet</span>
<span class="kn">from</span> <span class="nn">common.optimizer</span> <span class="kn">import</span> <span class="n">SGD</span>


<span class="c1"># 0. MNIST 데이터 읽기==========
</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">train_size</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">max_iterations</span> <span class="o">=</span> <span class="mi">2000</span>


<span class="c1"># 1. 실험용 설정==========
</span><span class="n">weight_init_types</span> <span class="o">=</span> <span class="p">{</span><span class="s">'std=0.01'</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span> <span class="s">'Xavier'</span><span class="p">:</span> <span class="s">'sigmoid'</span><span class="p">,</span> <span class="s">'He'</span><span class="p">:</span> <span class="s">'relu'</span><span class="p">}</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="n">networks</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">train_loss</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">weight_type</span> <span class="ow">in</span> <span class="n">weight_init_types</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">networks</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">MultiLayerNet</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">hidden_size_list</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
                                  <span class="n">output_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">weight_init_std</span><span class="o">=</span><span class="n">weight_type</span><span class="p">)</span>
    <span class="n">train_loss</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>


<span class="c1"># 2. 훈련 시작==========
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iterations</span><span class="p">):</span>
    <span class="n">batch_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">x_batch</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>
    <span class="n">t_batch</span> <span class="o">=</span> <span class="n">t_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>
    
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">weight_init_types</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">networks</span><span class="p">[</span><span class="n">key</span><span class="p">].</span><span class="n">gradient</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="n">networks</span><span class="p">[</span><span class="n">key</span><span class="p">].</span><span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">)</span>
    
        <span class="n">loss</span> <span class="o">=</span> <span class="n">networks</span><span class="p">[</span><span class="n">key</span><span class="p">].</span><span class="n">loss</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">)</span>
        <span class="n">train_loss</span><span class="p">[</span><span class="n">key</span><span class="p">].</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"==========="</span> <span class="o">+</span> <span class="s">"iteration:"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s">"==========="</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">weight_init_types</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">networks</span><span class="p">[</span><span class="n">key</span><span class="p">].</span><span class="n">loss</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="n">key</span> <span class="o">+</span> <span class="s">":"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">loss</span><span class="p">))</span>


<span class="c1"># 3. 그래프 그리기==========
</span><span class="n">markers</span> <span class="o">=</span> <span class="p">{</span><span class="s">'std=0.01'</span><span class="p">:</span> <span class="s">'o'</span><span class="p">,</span> <span class="s">'Xavier'</span><span class="p">:</span> <span class="s">'s'</span><span class="p">,</span> <span class="s">'He'</span><span class="p">:</span> <span class="s">'D'</span><span class="p">}</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">max_iterations</span><span class="p">)</span>
<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">weight_init_types</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">smooth_curve</span><span class="p">(</span><span class="n">train_loss</span><span class="p">[</span><span class="n">key</span><span class="p">]),</span> <span class="n">marker</span><span class="o">=</span><span class="n">markers</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">markevery</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"iterations"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>===========iteration:1800===========
std=0.01:2.2988839990272347
Xavier:0.35191173163622136
He:0.31074030545254105
===========iteration:1900===========
std=0.01:2.3098618922506837
Xavier:0.26615511258213476
He:0.1868492795884273
</pre></table></code></div></div><p><img data-src="/assets/img/Chapter6/output_61_1.png" alt="png" data-proofer-ignore></p><h2 id="63-배치-정규화"><span class="mr-2">6.3 배치 정규화</span><a href="#63-배치-정규화" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="631-배치-정규화-알고리즘"><span class="mr-2">6.3.1 배치 정규화 알고리즘</span><a href="#631-배치-정규화-알고리즘" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>배치 정규화가 주목받는 이유</p><ul><li>학습 속도 개선<li>초깃값에 크게 의존하지 않는다.<li>오버피팅 억제</ul><p>배치 정규화(batch normalization)</p><ul><li>학습 시 미니배치 단위로 정규화<li>각 층에서의 활성화값이 적당히 분포되도록 강제한다.<li>신경망 중간에 배치 정규화 계층을 삽입 <img data-src="https://t1.daumcdn.net/cfile/tistory/997AE03A5AAAA64C2A" data-proofer-ignore><li>수식 \(\mu_B \leftarrow \frac 1 m \sum^m_{i=1} x_i\)</ul>\[\sigma^2_B \leftarrow \sum^m_{i=1} (x_i - \mu_B)^2\]<p>\(\hat {x}_i \leftarrow \frac {x_i - \mu_B} {\sqrt {\sigma^2_B + \epsilon}}\)</p><ul><li>미니 배치의 평균이 0, 분산이 1이 되도록 정규화<li>$\epsilon$은 0으로 나누는 것을 방지(10e-7과 같은 매우 작은 값 사용)<li>활성화 함수 앞이나 뒤에 삽입<li>배치 정규화 계층마다 정규화된 데이터에 고유한 확대와 이동 변환을 수행한다. \(y_i \leftarrow \gamma \hat{x}_i + \beta\)<li>$\gamma$: 확대, $\beta$: 이동 <img data-src="https://mblogthumb-phinf.pstatic.net/MjAxNzA3MjdfMjYx/MDAxNTAxMTI5MDU1Mzg0.lsuyZE7qxn42sz10-EPOhwx0pTaXF9X0o8UCjI4LDS8g.nl-o2tc5upQvairyHQUU1RjZg5aUz2e9xu5KfbIHjBwg.PNG.cjswo9207/fig_6-17.png?type=w2" data-proofer-ignore></ul><center><small>▲ 배치 정규화 계산 그래프</small></center><h3 id="632-배치-정규화의-효과"><span class="mr-2">6.3.2 배치 정규화의 효과</span><a href="#632-배치-정규화의-효과" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>MNIST 데이터셋을 사용하여 비교</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
</pre><td class="rouge-code"><pre><span class="c1"># coding: utf-8
</span><span class="kn">import</span> <span class="nn">sys</span><span class="p">,</span> <span class="n">os</span>
<span class="n">sys</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">pardir</span><span class="p">)</span>  <span class="c1"># 부모 디렉터리의 파일을 가져올 수 있도록 설정
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">dataset.mnist</span> <span class="kn">import</span> <span class="n">load_mnist</span>
<span class="kn">from</span> <span class="nn">common.multi_layer_net_extend</span> <span class="kn">import</span> <span class="n">MultiLayerNetExtend</span>
<span class="kn">from</span> <span class="nn">common.optimizer</span> <span class="kn">import</span> <span class="n">SGD</span><span class="p">,</span> <span class="n">Adam</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># 학습 데이터를 줄임
</span><span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[:</span><span class="mi">1000</span><span class="p">]</span>
<span class="n">t_train</span> <span class="o">=</span> <span class="n">t_train</span><span class="p">[:</span><span class="mi">1000</span><span class="p">]</span>

<span class="n">max_epochs</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>


<span class="k">def</span> <span class="nf">__train</span><span class="p">(</span><span class="n">weight_init_std</span><span class="p">):</span>
    <span class="n">bn_network</span> <span class="o">=</span> <span class="n">MultiLayerNetExtend</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">hidden_size_list</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
                                    <span class="n">weight_init_std</span><span class="o">=</span><span class="n">weight_init_std</span><span class="p">,</span> <span class="n">use_batchnorm</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">MultiLayerNetExtend</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">hidden_size_list</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                <span class="n">weight_init_std</span><span class="o">=</span><span class="n">weight_init_std</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    
    <span class="n">train_acc_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">bn_train_acc_list</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="n">iter_per_epoch</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">train_size</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">epoch_cnt</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000000000</span><span class="p">):</span>
        <span class="n">batch_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">x_batch</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>
        <span class="n">t_batch</span> <span class="o">=</span> <span class="n">t_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>
    
        <span class="k">for</span> <span class="n">_network</span> <span class="ow">in</span> <span class="p">(</span><span class="n">bn_network</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
            <span class="n">grads</span> <span class="o">=</span> <span class="n">_network</span><span class="p">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">)</span>
            <span class="n">optimizer</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="n">_network</span><span class="p">.</span><span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">)</span>
    
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">iter_per_epoch</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">train_acc</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">)</span>
            <span class="n">bn_train_acc</span> <span class="o">=</span> <span class="n">bn_network</span><span class="p">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">)</span>
            <span class="n">train_acc_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_acc</span><span class="p">)</span>
            <span class="n">bn_train_acc_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">bn_train_acc</span><span class="p">)</span>
    
            <span class="k">print</span><span class="p">(</span><span class="s">"epoch:"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">epoch_cnt</span><span class="p">)</span> <span class="o">+</span> <span class="s">" | "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">train_acc</span><span class="p">)</span> <span class="o">+</span> <span class="s">" - "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bn_train_acc</span><span class="p">))</span>
    
            <span class="n">epoch_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">epoch_cnt</span> <span class="o">&gt;=</span> <span class="n">max_epochs</span><span class="p">:</span>
                <span class="k">break</span>
                
    <span class="k">return</span> <span class="n">train_acc_list</span><span class="p">,</span> <span class="n">bn_train_acc_list</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
</pre><td class="rouge-code"><pre><span class="c1"># 그래프 그리기==========
</span><span class="n">weight_scale_list</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">max_epochs</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">weight_scale_list</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span> <span class="s">"============== "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="s">"/16"</span> <span class="o">+</span> <span class="s">" =============="</span><span class="p">)</span>
    <span class="n">train_acc_list</span><span class="p">,</span> <span class="n">bn_train_acc_list</span> <span class="o">=</span> <span class="n">__train</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"W:"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">w</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">15</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">bn_train_acc_list</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Batch Normalization'</span><span class="p">,</span> <span class="n">markevery</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">train_acc_list</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s">"--"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Normal(without BatchNorm)'</span><span class="p">,</span> <span class="n">markevery</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">bn_train_acc_list</span><span class="p">,</span> <span class="n">markevery</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">train_acc_list</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">"--"</span><span class="p">,</span> <span class="n">markevery</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">4</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">yticks</span><span class="p">([])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"accuracy"</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">12</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">([])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"epochs"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'lower right'</span><span class="p">)</span>
    
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre><td class="rouge-code"><pre>============== 1/16 ==============
epoch:0 | 0.093 - 0.11
epoch:1 | 0.097 - 0.093


C:\Users\KJK\Anaconda3\lib\site-packages\numpy\core\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

epoch:10 | 0.116 - 0.41
epoch:11 | 0.116 - 0.414
epoch:12 | 0.116 - 0.421
epoch:13 | 0.116 - 0.421
epoch:14 | 0.116 - 0.42
epoch:15 | 0.116 - 0.421
epoch:16 | 0.116 - 0.506
epoch:17 | 0.116 - 0.509
epoch:18 | 0.116 - 0.512
epoch:19 | 0.116 - 0.511
</pre></table></code></div></div><p><img data-src="/assets/img/Chapter6/output_67_33.png" alt="png" data-proofer-ignore></p><ul><li>실선이 배치 정규화를 사용한 경우, 점선이 사용하지 않은 경우<li>거의 모든 경우에서 배치 정규화를 사용한 것이 학습 진도가 빠름</ul><h2 id="64-바른-학습을-위해"><span class="mr-2">6.4 바른 학습을 위해</span><a href="#64-바른-학습을-위해" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="641-오버피팅"><span class="mr-2">6.4.1 오버피팅</span><a href="#641-오버피팅" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>신경망이 훈련 데이터에만 지나치게 적응되어 그 외의 데이터에는 제대로 대응하지 못하는 상태<li>발생 원인<ul><li>매개변수가 많고 표현력이 높은 모델<li>훈련 데이터가 적음</ul></ul><p>MNIST로 실험</p><ul><li>300개의 훈련 데이터<li>7층 네트워크<li>각층의 뉴런은 100개<li>ReLU 활성화 함수</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># 오버피팅을 재현하기 위해 학습 데이터 수를 줄임
</span><span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[:</span><span class="mi">300</span><span class="p">]</span>
<span class="n">t_train</span> <span class="o">=</span> <span class="n">t_train</span><span class="p">[:</span><span class="mi">300</span><span class="p">]</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
</pre><td class="rouge-code"><pre><span class="n">network</span> <span class="o">=</span> <span class="n">MultiLayerNet</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">hidden_size_list</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="n">max_epochs</span> <span class="o">=</span> <span class="mi">201</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">train_loss_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_acc_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_acc_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">iter_per_epoch</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">train_size</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">epoch_cnt</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000000000</span><span class="p">):</span>
    <span class="n">batch_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">x_batch</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>
    <span class="n">t_batch</span> <span class="o">=</span> <span class="n">t_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>
    
    <span class="n">grads</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="n">network</span><span class="p">.</span><span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">iter_per_epoch</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">train_acc</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">)</span>
        <span class="n">test_acc</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span>
        <span class="n">train_acc_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_acc</span><span class="p">)</span>
        <span class="n">test_acc_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_acc</span><span class="p">)</span>
        
        <span class="n">epoch_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">epoch_cnt</span> <span class="o">&gt;=</span> <span class="n">max_epochs</span><span class="p">:</span>
            <span class="k">break</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">201</span><span class="p">),</span> <span class="n">train_acc_list</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">"o"</span><span class="p">,</span> <span class="n">markevery</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">201</span><span class="p">),</span> <span class="n">test_acc_list</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">"s"</span><span class="p">,</span> <span class="n">markevery</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"epochs"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"accuracy"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">((</span><span class="s">"train"</span><span class="p">,</span> <span class="s">"test"</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s">"lower right"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img data-src="/assets/img/Chapter6/output_73_0.png" alt="png" data-proofer-ignore></p><h3 id="642-가중치-감소weigth-decay"><span class="mr-2">6.4.2 가중치 감소(weigth decay)</span><a href="#642-가중치-감소weigth-decay" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>큰 가중치에 대해서는 그에 상응하는 큰 페널티를 부과하여 오버피팅 억제<li>손실함수에 L2 노름을 더해서 가중치가 커지는 것을 억제<ul><li>L2 이외에 L1, L$\infty$ 노름을 정규화 항으로 사용할 수 있다.</ul><li>손실함수에 $\frac 1 2 \lambda \mathbf{W}^2$를 더한다.<ul><li>$\lambda$: 정규화 세기 조절하는 하이퍼파라미터<li>$\frac 1 2$: 미분 결과인 $\lambda \mathbf{W}$을 조정하는 역할의 상수</ul></ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
</pre><td class="rouge-code"><pre><span class="c1"># coding: utf-8
</span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="n">sys</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">pardir</span><span class="p">)</span>  <span class="c1"># 부모 디렉터리의 파일을 가져올 수 있도록 설정
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">dataset.mnist</span> <span class="kn">import</span> <span class="n">load_mnist</span>
<span class="kn">from</span> <span class="nn">common.multi_layer_net</span> <span class="kn">import</span> <span class="n">MultiLayerNet</span>
<span class="kn">from</span> <span class="nn">common.optimizer</span> <span class="kn">import</span> <span class="n">SGD</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># 오버피팅을 재현하기 위해 학습 데이터 수를 줄임
</span><span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[:</span><span class="mi">300</span><span class="p">]</span>
<span class="n">t_train</span> <span class="o">=</span> <span class="n">t_train</span><span class="p">[:</span><span class="mi">300</span><span class="p">]</span>

<span class="c1"># weight decay（가중치 감쇠） 설정 =======================
#weight_decay_lambda = 0 # weight decay를 사용하지 않을 경우
</span><span class="n">weight_decay_lambda</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="c1"># ====================================================
</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">MultiLayerNet</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">hidden_size_list</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                        <span class="n">weight_decay_lambda</span><span class="o">=</span><span class="n">weight_decay_lambda</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span> <span class="c1"># 학습률이 0.01인 SGD로 매개변수 갱신
</span>
<span class="n">max_epochs</span> <span class="o">=</span> <span class="mi">201</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">train_loss_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_acc_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_acc_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">iter_per_epoch</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">train_size</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">epoch_cnt</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000000000</span><span class="p">):</span>
    <span class="n">batch_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">x_batch</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>
    <span class="n">t_batch</span> <span class="o">=</span> <span class="n">t_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>

    <span class="n">grads</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="n">network</span><span class="p">.</span><span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">iter_per_epoch</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">train_acc</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">)</span>
        <span class="n">test_acc</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span>
        <span class="n">train_acc_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_acc</span><span class="p">)</span>
        <span class="n">test_acc_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_acc</span><span class="p">)</span>

        <span class="k">print</span><span class="p">(</span><span class="s">"epoch:"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">epoch_cnt</span><span class="p">)</span> <span class="o">+</span> <span class="s">", train acc:"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">train_acc</span><span class="p">)</span> <span class="o">+</span> <span class="s">", test acc:"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">test_acc</span><span class="p">))</span>

        <span class="n">epoch_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">epoch_cnt</span> <span class="o">&gt;=</span> <span class="n">max_epochs</span><span class="p">:</span>
            <span class="k">break</span>


<span class="c1"># 그래프 그리기==========
</span><span class="n">markers</span> <span class="o">=</span> <span class="p">{</span><span class="s">'train'</span><span class="p">:</span> <span class="s">'o'</span><span class="p">,</span> <span class="s">'test'</span><span class="p">:</span> <span class="s">'s'</span><span class="p">}</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">max_epochs</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">train_acc_list</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'train'</span><span class="p">,</span> <span class="n">markevery</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">test_acc_list</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'s'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'test'</span><span class="p">,</span> <span class="n">markevery</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"epochs"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"accuracy"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'lower right'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre>epoch:195, train acc:0.9266666666666666, test acc:0.7279
epoch:196, train acc:0.9366666666666666, test acc:0.7276
epoch:197, train acc:0.9333333333333333, test acc:0.7267
epoch:198, train acc:0.9333333333333333, test acc:0.7261
epoch:199, train acc:0.93, test acc:0.7252
epoch:200, train acc:0.9333333333333333, test acc:0.7246
</pre></table></code></div></div><p><img data-src="/assets/img/Chapter6/output_76_1.png" alt="png" data-proofer-ignore></p><p>여전히 차이는 있지만 이전과 비교하면 차이가 줄어들었다.</p><h3 id="643-드롭아웃dropout"><span class="mr-2">6.4.3 드롭아웃(dropout)</span><a href="#643-드롭아웃dropout" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>은닉층의 뉴런을 임의로 삭제하면서 학습하는 방법<li>시험 때는 각 뉴런의 출력에 훈련 때 삭제 안 한 비율을 곱하여 출력</ul><p><img data-src="https://mblogthumb-phinf.pstatic.net/MjAxNzA3MjdfMjEz/MDAxNTAxMTMzMzE4MDAz.ZAl6mcZ7VvWhLR82U6dovtoNeLbbmFHCGupK5hcJICAg.Z0wpOnQUwMLHuddn3XdFhgT-ghnzT8NHzZMbB4pFWcIg.PNG.cjswo9207/fig_6-22.png?type=w2" data-proofer-ignore></p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">Dropout</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dropout_ratio</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout_ratio</span> <span class="o">=</span> <span class="n">dropout_ratio</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">mask</span> <span class="o">=</span> <span class="bp">None</span>
        
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">train_flg</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">train_flg</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="o">*</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout_ratio</span>
            <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">mask</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout_ratio</span><span class="p">)</span>
        
        
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dout</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">dout</span> <span class="o">*</span> <span class="bp">self</span><span class="p">,</span><span class="n">mask</span>
</pre></table></code></div></div><ul><li>self.mask: 삭제할 뉴런을 False로 표시<li>순전파 때 통과시키는 뉴런은 역전파 때도 신호를 그대로 통과시키고, 순전파 때 통과시키지 않은 뉴런은 역전파 때도 신호를 차단</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
</pre><td class="rouge-code"><pre><span class="c1"># coding: utf-8
</span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="n">sys</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">pardir</span><span class="p">)</span>  <span class="c1"># 부모 디렉터리의 파일을 가져올 수 있도록 설정
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">dataset.mnist</span> <span class="kn">import</span> <span class="n">load_mnist</span>
<span class="kn">from</span> <span class="nn">common.multi_layer_net_extend</span> <span class="kn">import</span> <span class="n">MultiLayerNetExtend</span>
<span class="kn">from</span> <span class="nn">common.trainer</span> <span class="kn">import</span> <span class="n">Trainer</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># 오버피팅을 재현하기 위해 학습 데이터 수를 줄임
</span><span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[:</span><span class="mi">300</span><span class="p">]</span>
<span class="n">t_train</span> <span class="o">=</span> <span class="n">t_train</span><span class="p">[:</span><span class="mi">300</span><span class="p">]</span>

<span class="c1"># 드롭아웃 사용 유무와 비울 설정 ========================
</span><span class="n">use_dropout</span> <span class="o">=</span> <span class="bp">True</span>  <span class="c1"># 드롭아웃을 쓰지 않을 때는 False
</span><span class="n">dropout_ratio</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="c1"># ====================================================
</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">MultiLayerNetExtend</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">hidden_size_list</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
                              <span class="n">output_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">use_dropout</span><span class="o">=</span><span class="n">use_dropout</span><span class="p">,</span> <span class="n">dropout_ration</span><span class="o">=</span><span class="n">dropout_ratio</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">,</span>
                  <span class="n">epochs</span><span class="o">=</span><span class="mi">301</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                  <span class="n">optimizer</span><span class="o">=</span><span class="s">'sgd'</span><span class="p">,</span> <span class="n">optimizer_param</span><span class="o">=</span><span class="p">{</span><span class="s">'lr'</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">},</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">trainer</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>

<span class="n">train_acc_list</span><span class="p">,</span> <span class="n">test_acc_list</span> <span class="o">=</span> <span class="n">trainer</span><span class="p">.</span><span class="n">train_acc_list</span><span class="p">,</span> <span class="n">trainer</span><span class="p">.</span><span class="n">test_acc_list</span>

<span class="c1"># 그래프 그리기==========
</span><span class="n">markers</span> <span class="o">=</span> <span class="p">{</span><span class="s">'train'</span><span class="p">:</span> <span class="s">'o'</span><span class="p">,</span> <span class="s">'test'</span><span class="p">:</span> <span class="s">'s'</span><span class="p">}</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_acc_list</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">train_acc_list</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'train'</span><span class="p">,</span> <span class="n">markevery</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">test_acc_list</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'s'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'test'</span><span class="p">,</span> <span class="n">markevery</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"epochs"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"accuracy"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'lower right'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>=== epoch:301, train acc:0.69, test acc:0.5264 ===
train loss:1.0455480803766772
train loss:1.140440368675071
=============== Final Test Accuracy ===============
test acc:0.5259
</pre></table></code></div></div><p><img data-src="/assets/img/Chapter6/output_82_1.png" alt="png" data-proofer-ignore></p><ul><li>앙상블 학습: 개별적으로 학습시킨 여러 모델의 출력을 평균 내어 추론하는 방식<li>드롭아웃으로 앙상블과 유사한 효과를 낼 수 있다.</ul><h2 id="65-적절한-하이퍼파라미터-값-찾기"><span class="mr-2">6.5 적절한 하이퍼파라미터 값 찾기</span><a href="#65-적절한-하이퍼파라미터-값-찾기" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>하이퍼파라미터</p><ul><li>각 층의 뉴런 수<li>배치 크기<li>학습률<li>가중치 감소 등</ul><h3 id="651-검증-데이터"><span class="mr-2">6.5.1 검증 데이터</span><a href="#651-검증-데이터" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>하이퍼파라미터의 성능을 평가할 때는 시험 데이터를 사용해선 안 된다.<ul><li>이유: 하이퍼파라미터 값이 시험 데이터에 오버피팅되기 때문</ul><li><strong>검증 데이터(validation data)</strong>: 훈련 데이터에서 분리해서 하이퍼파라미터의 성능 평가</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="c1"># coding: utf-8
</span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="n">sys</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">pardir</span><span class="p">)</span>  <span class="c1"># 부모 디렉터리의 파일을 가져올 수 있도록 설정
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">common.util</span> <span class="kn">import</span> <span class="n">shuffle_dataset</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">()</span>

<span class="c1"># 훈련 데이터를 뒤섞는다.
</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span> <span class="o">=</span> <span class="n">shuffle_dataset</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">)</span>

<span class="c1"># 20%를 검증 데이터로 분할
</span><span class="n">validation_rate</span> <span class="o">=</span> <span class="mf">0.20</span>
<span class="n">validation_num</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">x_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">validation_rate</span><span class="p">)</span>

<span class="n">x_val</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[:</span><span class="n">validation_num</span><span class="p">]</span>
<span class="n">t_val</span> <span class="o">=</span> <span class="n">t_train</span><span class="p">[:</span><span class="n">validation_num</span><span class="p">]</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">validation_num</span><span class="p">:]</span>
<span class="n">t_train</span> <span class="o">=</span> <span class="n">t_train</span><span class="p">[</span><span class="n">validation_num</span><span class="p">:]</span>
</pre></table></code></div></div><ul><li>데이터 분리 전에 입력 데이터와 정답 레이블을 뒤섞어야 한다. 데이터셋 안의 데이터가 치우쳐 있을 수도 있기 때문</ul><h3 id="652-하이퍼파라미터-최적화"><span class="mr-2">6.5.2 하이퍼파라미터 최적화</span><a href="#652-하이퍼파라미터-최적화" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>그리드 서치보다 랜덤 서치가 더욱 좋은 결과를 낸다.<li>대략적인 범위를 설정하고 점차 줄여나간다. 로그 스케일로 지정</ul><p>과정</p><ul><li>0단계<br /> 하이퍼파라미터 값의 범위를 설정한다.<li>1단계<br /> 설정된 범위에서 하이퍼파라미터의 값을 무작위로 추출한다.<li>2단계<br /> 1단계에서 샘플링한 하이퍼파라미터 값을 사용하여 학습하고, 검증 데이터로 정확도를 평가한다(에폭은 작게)<li>3단계<br /> 1단계와 2단계를 특정 횟수 반복하며, 그 정확도의 결과를 보고 하이퍼파라미터의 범위를 좁힌다.</ul><p><strong>베이즈 최적화(Bayesian optimization)</strong>를 이용해서 효율적 최적화를 수행할 수 있다.</p><h3 id="653-하이퍼파라미터-최적화-구현하기"><span class="mr-2">6.5.3 하이퍼파라미터 최적화 구현하기</span><a href="#653-하이퍼파라미터-최적화-구현하기" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>학습률과 가중치 감소 계수 탐색하는 문제</p><ul><li>가중치 감소 계수: $10^{-8}$~$10^{-4}$<li>학습률: $10^{-6}$~$10^{-2}$</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
</pre><td class="rouge-code"><pre><span class="c1"># coding: utf-8
</span><span class="kn">import</span> <span class="nn">sys</span><span class="p">,</span> <span class="n">os</span>
<span class="n">sys</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">pardir</span><span class="p">)</span>  <span class="c1"># 부모 디렉터리의 파일을 가져올 수 있도록 설정
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">dataset.mnist</span> <span class="kn">import</span> <span class="n">load_mnist</span>
<span class="kn">from</span> <span class="nn">common.multi_layer_net</span> <span class="kn">import</span> <span class="n">MultiLayerNet</span>
<span class="kn">from</span> <span class="nn">common.util</span> <span class="kn">import</span> <span class="n">shuffle_dataset</span>
<span class="kn">from</span> <span class="nn">common.trainer</span> <span class="kn">import</span> <span class="n">Trainer</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># 결과를 빠르게 얻기 위해 훈련 데이터를 줄임
</span><span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[:</span><span class="mi">500</span><span class="p">]</span>
<span class="n">t_train</span> <span class="o">=</span> <span class="n">t_train</span><span class="p">[:</span><span class="mi">500</span><span class="p">]</span>

<span class="c1"># 20%를 검증 데이터로 분할
</span><span class="n">validation_rate</span> <span class="o">=</span> <span class="mf">0.20</span>
<span class="n">validation_num</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">x_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">validation_rate</span><span class="p">)</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span> <span class="o">=</span> <span class="n">shuffle_dataset</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">)</span>
<span class="n">x_val</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[:</span><span class="n">validation_num</span><span class="p">]</span>
<span class="n">t_val</span> <span class="o">=</span> <span class="n">t_train</span><span class="p">[:</span><span class="n">validation_num</span><span class="p">]</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">validation_num</span><span class="p">:]</span>
<span class="n">t_train</span> <span class="o">=</span> <span class="n">t_train</span><span class="p">[</span><span class="n">validation_num</span><span class="p">:]</span>


<span class="k">def</span> <span class="nf">__train</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">,</span> <span class="n">epocs</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">MultiLayerNet</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">hidden_size_list</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
                            <span class="n">output_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">weight_decay_lambda</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">)</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">,</span> <span class="n">x_val</span><span class="p">,</span> <span class="n">t_val</span><span class="p">,</span>
                      <span class="n">epochs</span><span class="o">=</span><span class="n">epocs</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                      <span class="n">optimizer</span><span class="o">=</span><span class="s">'sgd'</span><span class="p">,</span> <span class="n">optimizer_param</span><span class="o">=</span><span class="p">{</span><span class="s">'lr'</span><span class="p">:</span> <span class="n">lr</span><span class="p">},</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">trainer</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">trainer</span><span class="p">.</span><span class="n">test_acc_list</span><span class="p">,</span> <span class="n">trainer</span><span class="p">.</span><span class="n">train_acc_list</span>


<span class="c1"># 하이퍼파라미터 무작위 탐색======================================
</span><span class="n">optimization_trial</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">results_val</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">results_train</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">optimization_trial</span><span class="p">):</span>
    <span class="c1"># 탐색한 하이퍼파라미터의 범위 지정===============
</span>    <span class="n">weight_decay</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">**</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">**</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
    <span class="c1"># ================================================
</span>
    <span class="n">val_acc_list</span><span class="p">,</span> <span class="n">train_acc_list</span> <span class="o">=</span> <span class="n">__train</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"val acc:"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">val_acc_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="s">" | lr:"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span> <span class="o">+</span> <span class="s">", weight decay:"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">weight_decay</span><span class="p">))</span>
    <span class="n">key</span> <span class="o">=</span> <span class="s">"lr:"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span> <span class="o">+</span> <span class="s">", weight decay:"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">weight_decay</span><span class="p">)</span>
    <span class="n">results_val</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">val_acc_list</span>
    <span class="n">results_train</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_acc_list</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre><td class="rouge-code"><pre><span class="c1"># 그래프 그리기========================================================
</span><span class="k">print</span><span class="p">(</span><span class="s">"=========== Hyper-Parameter Optimization Result ==========="</span><span class="p">)</span>
<span class="n">graph_draw_num</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">col_num</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">row_num</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">graph_draw_num</span> <span class="o">/</span> <span class="n">col_num</span><span class="p">))</span>
<span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val_acc_list</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">results_val</span><span class="p">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Best-"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="s">"(val acc:"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">val_acc_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="s">") | "</span> <span class="o">+</span> <span class="n">key</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">row_num</span><span class="p">,</span> <span class="n">col_num</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Best-"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">5</span><span class="p">:</span> <span class="n">plt</span><span class="p">.</span><span class="n">yticks</span><span class="p">([])</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">([])</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">val_acc_list</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">val_acc_list</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">results_train</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="s">"--"</span><span class="p">)</span>
    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">graph_draw_num</span><span class="p">:</span>
        <span class="k">break</span>

<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre><td class="rouge-code"><pre>=========== Hyper-Parameter Optimization Result ===========
Best-1(val acc:0.78) | lr:0.0077307054058675445, weight decay:2.5887086671429946e-05
Best-2(val acc:0.77) | lr:0.009154370132240392, weight decay:8.379491394743663e-05
Best-3(val acc:0.76) | lr:0.0098006673797611, weight decay:1.0450027144308723e-07
Best-4(val acc:0.72) | lr:0.007678681706710489, weight decay:1.7836457077216995e-07
Best-5(val acc:0.71) | lr:0.007626052918778914, weight decay:4.5307674366432563e-07
Best-6(val acc:0.65) | lr:0.004922531472247901, weight decay:1.7303188009642406e-07
Best-7(val acc:0.6) | lr:0.004816515317994456, weight decay:4.499890310553459e-07
Best-8(val acc:0.58) | lr:0.003990354694316797, weight decay:1.8853665087085003e-06
Best-9(val acc:0.55) | lr:0.0035304311414633004, weight decay:2.637284630879835e-07
Best-10(val acc:0.49) | lr:0.0030944498698391794, weight decay:8.008827389280176e-08
Best-11(val acc:0.48) | lr:0.0033599550676127856, weight decay:5.599030526130115e-07
Best-12(val acc:0.47) | lr:0.0046485659124741955, weight decay:4.803374416952201e-07
Best-13(val acc:0.44) | lr:0.005146752703310548, weight decay:1.921828499791707e-06
Best-14(val acc:0.43) | lr:0.0019810387426700033, weight decay:1.018064467263664e-07
Best-15(val acc:0.36) | lr:0.0031568644707760337, weight decay:9.852039867390541e-05
Best-16(val acc:0.34) | lr:0.001842499123551303, weight decay:1.476367368713895e-07
Best-17(val acc:0.32) | lr:0.0026945617175910246, weight decay:5.686409658051806e-05
Best-18(val acc:0.32) | lr:0.0024649675135479747, weight decay:6.70400523881945e-05
Best-19(val acc:0.24) | lr:0.002015741746864137, weight decay:9.886831062118664e-06
Best-20(val acc:0.23) | lr:0.0016390246367057597, weight decay:1.3720649280599984e-05
</pre></table></code></div></div><p><img data-src="/assets/img/Chapter6/output_96_1.png" alt="png" data-proofer-ignore></p><p>학습률은 $0.001$ ~ $0.01$, 가중치 감소 계수는 $10^{-8}$ ~ $10^{-6}$ 사이에서 학습이 잘 진행된다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>
</pre></table></code></div></div></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/ml/'>ML</a>, <a href='/categories/book-study/'>book_study</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/deep-learning/" class="post-tag no-text-decoration" >Deep_learning</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"></div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0+%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94+%EB%94%A5%EB%9F%AC%EB%8B%9D+Chapter06+-+Yh%27s+blog&url=https%3A%2F%2Fleeje008.github.io%2Fposts%2F%25EB%25B0%2591%25EB%25B0%2594%25EB%258B%25A5%25EB%25B6%2580%25ED%2584%25B0-%25EC%258B%259C%25EC%259E%2591%25ED%2595%2598%25EB%258A%2594-%25EB%2594%25A5%25EB%259F%25AC%25EB%258B%259D-Chapter06%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0+%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94+%EB%94%A5%EB%9F%AC%EB%8B%9D+Chapter06+-+Yh%27s+blog&u=https%3A%2F%2Fleeje008.github.io%2Fposts%2F%25EB%25B0%2591%25EB%25B0%2594%25EB%258B%25A5%25EB%25B6%2580%25ED%2584%25B0-%25EC%258B%259C%25EC%259E%2591%25ED%2595%2598%25EB%258A%2594-%25EB%2594%25A5%25EB%259F%25AC%25EB%258B%259D-Chapter06%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fleeje008.github.io%2Fposts%2F%25EB%25B0%2591%25EB%25B0%2594%25EB%258B%25A5%25EB%25B6%2580%25ED%2584%25B0-%25EC%258B%259C%25EC%259E%2591%25ED%2595%2598%25EB%258A%2594-%25EB%2594%25A5%25EB%259F%25AC%25EB%258B%259D-Chapter06%2F&text=%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0+%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94+%EB%94%A5%EB%9F%AC%EB%8B%9D+Chapter06+-+Yh%27s+blog" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div><script src="https://utteranc.es/client.js" repo="leeje008/leeje008.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter02/">밑바닥부터 시작하는 딥러닝 Chapter02</a><li><a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter03/">밑바닥부터 시작하는 딥러닝 Chapter03</a><li><a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter04/">밑바닥부터 시작하는 딥러닝 Chapter04</a><li><a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter06/">밑바닥부터 시작하는 딥러닝 Chapter06</a><li><a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter07/">밑바닥부터 시작하는 딥러닝 Chapter07</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/deep-learning/">Deep_learning</a> <a class="post-tag" href="/tags/subject-project/">subject_project</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4"><div id="related-posts" class="mb-2 mb-sm-4"><h3 class="pt-2 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter02/"><div class="card-body"> <em class="small" data-ts="1636815600" data-df="ll" > Nov 14, 2021 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>밑바닥부터 시작하는 딥러닝 Chapter02</h3><div class="text-muted small"><p> 퍼셉트론 퍼셉트론 perceptron 알고리즘. 프랑크 로젠블라트가 1957년 고안한 알고리즘이고, 신경망(딥러닝)의 기원이 되는 알고리즘이다. 퍼셉트론은 딥러닝으로 나아가는 데 중요한 아이디어를 준다. 퍼셉트론 다수의 신호를 입력으로 하나의 신호를 출력한다. 신호 : 전류나 강물처럼 흐름 1을 신호가 흐른다. 0을 신호가 흐...</p></div></div></a></div><div class="card"> <a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter03/"><div class="card-body"> <em class="small" data-ts="1636815600" data-df="ll" > Nov 14, 2021 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>밑바닥부터 시작하는 딥러닝 Chapter03</h3><div class="text-muted small"><p> 신경망 가중치 매개변수의 적절한 값을 데이터에서 자동으로 학습하는 능력이 신경망의 중요한 성질이다. 신경망의 개요, 신경망이 입력 데이터가 무엇인지 식별하는 처리 과정을 알아보자. 퍼셉트론에서 신경망으로 퍼셉트론과 다른 점으로 신경망 구조를 살펴보자. 신경망의 예 신경망 그림을 참고한다. 가장 왼쪽 줄을 입력층, 가장 오른쪽 줄을 출력층, ...</p></div></div></a></div><div class="card"> <a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter04/"><div class="card-body"> <em class="small" data-ts="1637334000" data-df="ll" > Nov 20, 2021 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>밑바닥부터 시작하는 딥러닝 Chapter04</h3><div class="text-muted small"><p> CH04 신경망 학습 학습이란? 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것을 의미함 4.1 데이터로부터 학습한다 =&amp;gt; 신경망의 주요한 특징 中 하나는 데이터를 통해 가중치가 결정된다! 퍼셉트론 수렴 정리 내용: 선형 분리 문제는 유한번의 학습을 통해 풀 수 있다! 정리 $ X^+,X^- 가\ 선형\ 분리\ 가능...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter05/" class="btn btn-outline-primary" prompt="Older"><p>밑바닥부터 시작하는 딥러닝 Chapter05</p></a> <a href="/posts/Oversampling/" class="btn btn-outline-primary" prompt="Newer"><p>Oversampling</p></a></div></div></div><footer class="row pl-3 pr-3"><div class="col-12 d-flex justify-content-between align-items-center text-muted pl-0 pr-0"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://github.com/leeje008">Koyounghun</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">All rights reserved</span></p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/deep-learning/">Deep_learning</a> <a class="post-tag" href="/tags/subject-project/">subject_project</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/ko.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script>
