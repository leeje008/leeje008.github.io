<!DOCTYPE html><html lang="ko" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="밑바닥부터 시작하는 딥러닝 Chapter04" /><meta property="og:locale" content="ko" /><meta name="description" content="CH04 신경망 학습" /><meta property="og:description" content="CH04 신경망 학습" /><link rel="canonical" href="https://leeje008.github.io/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter04/" /><meta property="og:url" content="https://leeje008.github.io/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter04/" /><meta property="og:site_name" content="Yh’s blog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-11-20T00:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="밑바닥부터 시작하는 딥러닝 Chapter04" /><meta name="twitter:site" content="@twitter_username" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-09-05T17:02:11+09:00","datePublished":"2021-11-20T00:00:00+09:00","description":"CH04 신경망 학습","headline":"밑바닥부터 시작하는 딥러닝 Chapter04","mainEntityOfPage":{"@type":"WebPage","@id":"https://leeje008.github.io/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter04/"},"url":"https://leeje008.github.io/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter04/"}</script><title>밑바닥부터 시작하는 딥러닝 Chapter04 | Yh's blog</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Yh's blog"><meta name="application-name" content="Yh's blog"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="/assets/img/me3.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Yh's blog</a></div><div class="site-subtitle font-italic">Final success will be made repeated attempts</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/leeje008" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['leeje008','naver.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="https://www.facebook.com/profile.php?id=100006983951106" aria-label="facebook" > <i class="fab fa-facebook"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>밑바닥부터 시작하는 딥러닝 Chapter04</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4 pb-5"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>밑바닥부터 시작하는 딥러닝 Chapter04</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1637334000" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Nov 20, 2021 </em> </span> <span> Updated <em class="" data-ts="1662364931" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Sep 5, 2022 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="https://github.com/leeje008">Koyounghun</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="4707 words"> <em>26 min</em> read</span></div></div></div><div class="post-content"><h1 id="ch04-신경망-학습">CH04 신경망 학습</h1><p>학습이란? 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것을 의미함</p><h2 id="41-데이터로부터-학습한다"><span class="mr-2">4.1 데이터로부터 학습한다</span><a href="#41-데이터로부터-학습한다" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>=&gt; 신경망의 주요한 특징 中 하나는 데이터를 통해 가중치가 결정된다!</p><h2 id="퍼셉트론-수렴-정리"><span class="mr-2">퍼셉트론 수렴 정리</span><a href="#퍼셉트론-수렴-정리" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>내용: 선형 분리 문제는 유한번의 학습을 통해 풀 수 있다!</p><h2 id="정리"><span class="mr-2">정리</span><a href="#정리" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>$ X^+,X^- 가\ 선형\ 분리\ 가능한\ train-set이라고\ 하자\ $ $ 이\ 때\ y를\ 다음과\ 같은\ 레이블이라\ 할\ 때 \ y_i = \pm1(x_i \in X^\pm)$ $ 전체\ train-set\ X = X^+ \cup X^-의$ $ N개의\ 데이터셋에\ 대해\ 다음과\ 같이\ 순서를\ 입력한다고\ 하자$ $ x(1),x(2), …..x(N),x(1),…..$ $ 즉,\ 마지막\ 데이터까지\ 학습이\ 끝나면\ 처음으로\ 다시\ 돌아가는\ 것을\ 의미함$ $ 정리 예측에\ 실패한\ 입력값을\ 다음과\ 같이\ 둔다고\ 할\ 때\ x_1,x_2,x_3….x_n$ $ w_1=0 즉\ 가중치\ 초기값을\ 0이라\ 할\ 때\ $ $ n번째\ 예측\ 실패한\ 데이터에\ 대해\ 다음과\ 같이\ 가중치를\ 업데이트\ 한다고\ 하면$ $ w_{n+1} = w_n + y_nx_n$ $ 그러면\ 다음\ 식을\ 만족하는\ n_0가\ 존재한다.$ $w_{n0} = w_{n0+1}=w_{n0+2} …..$</p><p>참고 링크: https://freshrimpsushi.github.io/posts/perceptron-convergence-theorem/</p><h2 id="411-데이터-주도-학습"><span class="mr-2">4.1.1 데이터 주도 학습</span><a href="#411-데이터-주도-학습" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>기계학습 =&gt;데이터에서 답을 찾고 데이터에서 패턴을 발견함 즉, 데이터가 핵심이라고 할 수 있음</p><p>신경망과 딥러닝은 기존의 기계학습에서 더 나아가 사람의 개입을 최소화해주는 기법이라고 할 수 있음</p><p><img data-src="/assets/img/2021-11-20-Chapter04/220px-MnistExamples.png" alt="220px-MnistExamples" data-proofer-ignore></p><p>다음과 같은 이미지의 분리 =&gt; 사람의 경우 손쉽게 가능 하지만 로짓을 짜는 것은 다른 문제임</p><p>기계학습에서 모아진 데이터로부터 규칙을 찾아내는 역할을 기계 즉 컴퓨터가 담당한다.</p><p>기존의 머신러닝 기법에서는 모델링은 사람이 설계하는 반면에 신경망 모형은 기계가 스스로 학습을 하게 된다.</p><p>따라서 딥러닝을 종단간 기계학습 (사람의 개입이 기존에 비해 최소화 되었다라는 의미를 내포함)이라고 한다.</p><h2 id="412-train-set과-test-set"><span class="mr-2">4.1.2 train-set과 test-set</span><a href="#412-train-set과-test-set" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>기계 학습에서는 데이터를 train-set과 test-set으로 나누게 된다.</p><p>있는 데이터를 전부 다 활용하는 것은 왜 안될까? =&gt; 일반화의 문제</p><p>즉 주어진 데이터에서만 학습을 잘하고 그 이외의 데이터에 대해서는 모델의 성능이 떨어지는 over-fitting 문제가 발생함</p><p>over-fitting은 대게 변수의 개수가 많을 때(차원의 저주라고 함) 발생하게 된다.</p><h1 id="42-손실-함수loss-function">4.2 손실 함수(Loss-function)</h1><p>손실 함수 =&gt; 현제 모델의 성능이 어떠한지 나타내는 지표 (정확히는 얼마나 나쁜지를 나타내는 지표)</p><p>가장 많이 사용되는 손실 함수로는 평균제곱오차(MSE)가 있음</p>\[E = {1 \over 2} \sum_{k}(y_k - t_k)^2\] \[이\ 때\ y_k는\ 신경망\ 모형의\ 추정값\ t_k는\ 정답\ 레이블을\ 의미함\]<p>평균 제곱오차를 python으로 구현하는 코드는 다음과 같다</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>
<span class="n">t</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="c1"># 평균제곱 오차의 구현
</span>
<span class="k">def</span> <span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">((</span><span class="n">y</span><span class="o">-</span><span class="n">t</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="c1"># 실제 사용
</span>
<span class="c1"># 실제 정답은 2인 상황
</span>
<span class="n">t</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

<span class="c1"># 예시: 2일 확률이 가장 높다고 추정함
</span><span class="n">y</span> <span class="o">=</span>  <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>

<span class="n">mean_squared_error</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">),</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">t</span><span class="p">))</span> <span class="c1">#y와t가 리스트 형태로 저장이 되어 있으므로 넘파이 배열로 변환 후 계산
</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>0.09750000000000003
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="c1"># 7일 확률이 가장 높다고 추정한 경우
</span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>

<span class="n">mean_squared_error</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">),</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>

<span class="c1"># 위의 예시로부터 정답을 맞추면 평균제곱오차가 줄어드는 것을 확인할 수 있음
</span></pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>0.5975
</pre></table></code></div></div><h2 id="422-cross-entropy"><span class="mr-2">4.2.2 cross-entropy</span><a href="#422-cross-entropy" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>신경망 모형에서 자주 사용되는 또 다른 손실 함수로 cross-entropy가 있음</p>\[E =- \sum_{k}t_k\log y_k\]<p>이 때 log는 일반적으로 자연상수 \(e\)를 의미함 즉 자연로그</p><p><img data-src="/assets/img/2021-11-20-Chapter04/다운로드 (1).png" alt="다운로드 (1)" data-proofer-ignore></p><p>위 그래프에서 확인이 가능하듯히 자연로그 함수는 0에 가까울수록 y의 값이 작아짐 (손실이 작아짐)</p><p>다음은 교차 엔트로피의 python 구현 코드</p>\[이\ 때\ 아주\ 작은\ 임의의\ 수를\ 더해주어\ -\infty 가\ 되는\ 것을\ 방지해\ 줌\]<div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="c1"># cross entropy 구현
</span>
<span class="k">def</span> <span class="nf">cross_entropy_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="mf">1e-7</span> <span class="c1"># 보정항
</span>    <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">t</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="o">+</span><span class="n">delta</span><span class="p">))</span>

<span class="n">t</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

<span class="n">y</span> <span class="o">=</span>  <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>

<span class="n">cross_entropy_error</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>0.510825457099338
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>

<span class="n">cross_entropy_error</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>2.302584092994546
</pre></table></code></div></div><h2 id="423-미니배치-학습"><span class="mr-2">4.2.3 미니배치 학습</span><a href="#423-미니배치-학습" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>모든 훈련 데이터의 손실 함수 공식은 다음과 같다.</p>\[E= -{1 \over N}\sum_{n}\sum_{k}t_{n,k} \log y_{n,k}\]<p>이는 단일 데이터의 손실 함수 공식을 전체 데이터의 개수 N개로 확장한 것이고, 마지막으로 데이터의 개수 N개로 나눠서</p><p>정규화된 손실함수를 구할 수 있다</p><p>하지만 일반적으로 모든 데이터의 손실함수를 구하는 것은 굉장한 computation 낭비가 발생하게 된다.</p><p>(예시에서는 60,000개의 데이터가 존재하고 일반적으로 빅데이터로 확장하게 되었을 때 계산량이 어마어마 해짐)</p><p>따라서 신경망 모형에서는 손실함수를 계산할 때 모든 훈련 데이터에 대해서 손실 함수를 구하지 않고</p><p>일부를 추출하여 (일종의 random-sampling 기법) 그 일부에 대해서만 손실 함수를 구하게 된다.</p><p>다음은 mnist 데이터에서 일부를 무작위로 골라내는 코드를 구현한 것임</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">sys</span><span class="p">,</span> <span class="n">os</span>
<span class="n">sys</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">pardir</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">dataset.mnist</span> <span class="kn">import</span> <span class="n">load_mnist</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="n">normalize</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">one_hot_label</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span> <span class="c1"># one-hot encdoing 방식으로 class를 범주화
</span>
<span class="k">print</span><span class="p">(</span><span class="n">x_train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>(60000, 784)
(60000, 10)
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="n">train_size</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">batch_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span> <span class="c1"># 무작위 추출
</span><span class="n">x_batch</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>
<span class="n">t_batch</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">6000</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="c1"># 딥러닝에서의 배치사이즈는 통계학에서의 샘플링과 동일한 의미를 지닌다고 볼 수 있음
</span></pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>array([ 333, 3044, 5502, 1494, 5039,  210, 1476, 2268,  245, 1344])
</pre></table></code></div></div><p>미니 배치 학습은 통계학에서의 sampling 기법을 적용한 것이라고 할 수 있음</p><p>통계학은 모집단의 정보를 추출하기 위해 모집단에서 표본을 추출하여 모집단의 정보를 추정하는데,</p><p>만약 적절한 표본 채집 방법과 표본의 개수를 적용한다면 굳이 모든 모집단의 표본을 가지고 있지 않아도</p><p>올바른 추정이 가능함</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="c1"># 배치용 cross_entropy 구현하기
</span>
<span class="k">def</span> <span class="nf">cross_entropy_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">y</span><span class="p">.</span><span class="n">dim</span> <span class="o">==</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">t</span><span class="p">.</span><span class="n">size</span><span class="p">)</span> <span class="c1"># y는 신경망에서의 추정값 t는 실제 정답 레이블을 의미하게 된다
</span>        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="p">.</span><span class="n">size</span><span class="p">)</span>
        
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">t</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="o">+</span><span class="mf">1e-7</span><span class="p">))</span> <span class="o">/</span> <span class="n">batch_size</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">cross_entropy_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">y</span><span class="p">.</span><span class="n">dim</span> <span class="o">==</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">t</span><span class="p">.</span><span class="n">size</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="p">.</span><span class="n">size</span><span class="p">)</span>
        
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">batch_size</span><span class="p">),</span> <span class="n">t</span><span class="p">]</span><span class="o">+</span><span class="mf">1e-7</span><span class="p">))</span> <span class="o">/</span> <span class="n">batch_size</span> <span class="c1"># 전체 훈련 데이터의 개수로 나눈 것이 아닌 batch_size로 나누게 된다.
</span></pre></table></code></div></div><h2 id="425-왜-손실함수를-설정하는가"><span class="mr-2">4.2.5 왜 손실함수를 설정하는가?</span><a href="#425-왜-손실함수를-설정하는가" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>신경망 모형에서 손실함수의 미분값을 기준으로 가중치를 갱신하는 방법을 사용함 (더 자세한 내용은 뒤에 다뤄질 듯)</p><p>따라서 정확도를 사용하게 된다면 거의 대부분의 미분 값이 0이 되기 때문에 가중치 갱신이 안된다 즉 훈련이 불가함</p><p>accuracy를 사용했을 때 미분값이 0이 된다는 것의 의미</p><p>=&gt; 가중치를 미세하게 조정하더라도 정확도의 값은 그대로 값을 유지하는 경우가 대다수가 될 것임</p><p>하지만 손실 함수를 선택할 경우 가중치의 미세한 조정에 따라서 손실 함수의 값 역시 지속적으로 변동이 되기 때문에</p><p>그에 대한 반응이 일어나고 미분으로 계산할 시 0이 아니게 된다. 즉 가중치의 갱신이 일어난다!</p><p><img data-src="/assets/img/2021-11-20-Chapter04/Untitled 6.png" alt="Untitled 6" data-proofer-ignore></p><h2 id="43-수치-미분"><span class="mr-2">4.3 수치 미분</span><a href="#43-수치-미분" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>미분의 의미 =&gt; 어떤 함수가 존재하고 어떤 지점이 있을 때 해당 지점에서의 순간 변화율을 의미함 수식으로는 다음과 같다.</p>\[\lim_{h \to 0}{f(x+h)-f(x) \over h}\] \[즉\ x의\ 작은\ 변화가\ f(x)를\ 얼마나\ 변화시키는가\ 를\ 나타낸다.\]<p>다음은 미분을 python으로 구현한 코드</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="c1"># 나쁜 코드의 예시
</span>
<span class="k">def</span> <span class="nf">numerical_diff</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="mf">10e-50</span>
    <span class="k">return</span> <span class="p">((</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">h</span><span class="p">))</span> <span class="o">-</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">/</span><span class="n">h</span> <span class="c1"># 프로그래밍에서의 반올림 오차를 발생하게 된다.
</span>
<span class="c1"># 반올림의 문제를 어느 정도 해결
</span>
<span class="k">def</span> <span class="nf">numerical_diff</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="mf">1e-4</span>
    <span class="k">return</span> <span class="p">((</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">h</span><span class="p">))</span> <span class="o">-</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">/</span><span class="n">h</span>
</pre></table></code></div></div><p>결국 python으로 미분을 구현하는 것은 수치 미분을 적용하는 것과 같음</p><p>why =&gt; 애초에 실제 손실 함수가 어떠한 수식으로 이루어 졌는지 정확하게 알아내는 것이 불가능함</p><p>그러므로 근사적으로 수치미분을 사용하여 신경망 모형의 가중치를 갱신하는 것이 타당할 것임</p><p>해석적 미분 =&gt; 실제 미분값을 의미 예를 들어 \({\partial \over \partial{x}} x^2 = 2x\)</p><p>수치 미분 =&gt;아주 작은 차분으로 미분하는 것을 의미 즉 위의 python code로 구현한 것을 의미한다고 보면 된다. (쉽게 말해 해석적 미분의 근사치)</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">function_1</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">0.01</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mf">0.1</span><span class="o">*</span><span class="n">x</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="n">plt</span>


<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">20.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">function_1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"X"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"f(X)"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img data-src="/assets/img/2021-11-20-Chapter04/다운로드.png" alt="다운로드" data-proofer-ignore></p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">numerical_diff</span><span class="p">(</span><span class="n">function_1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span> <span class="c1"># x = 5에서의 수치미분값
</span></pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>0.20000099999917254
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">numerical_diff</span><span class="p">(</span><span class="n">function_1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="c1"># x = 10에서의 수치미분값
</span></pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>0.3000009999976072
</pre></table></code></div></div><h2 id="433-편미분"><span class="mr-2">4.3.3 편미분</span><a href="#433-편미분" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>일반적으로 우리가 계산하고 미분해야할 손실 함수는 여러 가중치들의 함수로 표현이 된다.</p><p>이러한 여러 변수에 대한 미분을 적용하기 위한 방법으로 편미분 방법을 적용하는데,</p><p>함수를 다음과 같이 가정할 때 편미분은 다음과 같다.</p>\[f(x_0,x_1) = {x_0}^2 + {x_1}^2\] \[{\partial \over \partial{x_0}} f(x_0,x_1) = 2x_0\] \[{\partial \over \partial{x_1}} f(x_0,x_1) = 2x_1\]<p>이를 python으로 구현한 코드는 다음과 같다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">function_2</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">function_tmp1</span><span class="p">(</span><span class="n">x0</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x0</span><span class="o">*</span><span class="n">x0</span> <span class="o">+</span> <span class="mf">4.0</span><span class="o">**</span><span class="mf">2.0</span>

<span class="n">numerical_diff</span><span class="p">(</span><span class="n">function_tmp1</span><span class="p">,</span><span class="mf">3.0</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>6.000099999994291
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">function_tmp2</span><span class="p">(</span><span class="n">x1</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">3.0</span><span class="o">*</span><span class="mf">3.0</span> <span class="o">+</span> <span class="n">x1</span><span class="o">*</span><span class="n">x1</span>

<span class="n">numerical_diff</span><span class="p">(</span><span class="n">function_tmp2</span><span class="p">,</span><span class="mf">4.0</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>8.00009999998963
</pre></table></code></div></div><p>위의 함수의 그래프는 다음과 같이 그릴 수 있음</p><p><img data-src="/assets/img/2021-11-20-Chapter04/img.png" alt="img" data-proofer-ignore></p><h2 id="44-기울기"><span class="mr-2">4.4 기울기</span><a href="#44-기울기" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>기울기란? 여러 변수의 편미분 값의 vectorization 즉 여러 변수의 편미분 값을 벡터로 표현한 것이 기울기라고 할 수 있음</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">numerical_gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="mf">1e-4</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># x와 같은 형상의 배열을 생성
</span>    
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">):</span>
        <span class="n">tmp_val</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp_val</span> <span class="o">+</span> <span class="n">h</span>
        <span class="n">fxh1</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp_val</span> <span class="o">-</span><span class="n">h</span>
        <span class="n">fxh2</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="n">grad</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">fxh1</span> <span class="o">-</span> <span class="n">fxh2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">h</span><span class="p">)</span>
        <span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp_val</span>
        
    <span class="k">return</span> <span class="n">grad</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">numerical_gradient</span><span class="p">(</span><span class="n">function_2</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>array([6., 8.])
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">numerical_gradient</span><span class="p">(</span><span class="n">function_2</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">]))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>array([0., 4.])
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">numerical_gradient</span><span class="p">(</span><span class="n">function_2</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>array([6., 0.])
</pre></table></code></div></div><p>손실 함수를 convex-function으로 가정하게 된다면 해당 함수를 단면으로 자른 모습은 다음과 같다</p><p><img data-src="/assets/img/2021-11-20-Chapter04/다운로드 (1)-16384327461131.png" alt="다운로드 (1)-16384327461131" data-proofer-ignore></p><p>따라서 손실함수를 최솟값을 가지게 하려면 해당 위치에서 각각 편미분을 하여 벡터로 표현한 값에 -를 곱해주면</p><p>손실함수의 최소가 되는 지점으로 나아갈 수 있다.</p><p>이 것이 gradient-descent 방법이다.</p><p>(local_minimum 혹은 실제로 convex 형태가 아닐 가능성이 있는 문제가 있지만 이는 여기서 다루지 않고 후에 다루도록 한다.)</p><p>경사법을 수식으로 나타내면 다음과 같다.</p><p>\(x_0 =x_0 - \eta{\partial f \over \partial{x_0}}\) \(x_1 =x_1 - \eta{\partial f \over \partial{x_1}}\)</p><p>여기서 eta는 학습률(얼마나 나아갈 지를 의미)이다.</p><p>다음은 경사하강법의 구현</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">init_x</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">step_num</span> <span class="o">=</span> <span class="mi">100</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">init_x</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">step_num</span><span class="p">):</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">-=</span> <span class="n">lr</span><span class="o">*</span><span class="n">grad</span>
        
    <span class="k">return</span> <span class="n">x</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">function_2</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>

<span class="n">init_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">])</span>

<span class="n">gradient_descent</span><span class="p">(</span><span class="n">function_2</span><span class="p">,</span> <span class="n">init_x</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">step_num</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>array([-0.39785867,  0.53047822])
</pre></table></code></div></div><p>Note: 위에서와 같이 학습률과 같은 매개변수를 hyperparameter라 하는데 이는 사용자가 지정해야 함</p><p>optimal한 hyperparameter를 찾는 방식에 대해서는 이후에 포스팅을 할 예정</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="c1"># 학습률이 너무 큰 예
</span>
<span class="n">init_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">])</span>

<span class="n">gradient_descent</span><span class="p">(</span><span class="n">function_2</span><span class="p">,</span> <span class="n">init_x</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">step_num</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>array([-2.58983747e+13, -1.29524862e+12])
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="c1"># 학습률이 너무 작은 예
</span>
<span class="n">init_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">])</span>

<span class="n">gradient_descent</span><span class="p">(</span><span class="n">function_2</span><span class="p">,</span> <span class="n">init_x</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mf">1e-10</span><span class="p">,</span> <span class="n">step_num</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>array([-2.99999994,  3.99999992])
</pre></table></code></div></div><h2 id="442-신경망에서의-기울기"><span class="mr-2">4.4.2 신경망에서의 기울기</span><a href="#442-신경망에서의-기울기" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>신경망 학습에서의 기울기를 구하는 과정을 간단하게 수식으로 나타내면 다음과 같음 가중치를(2*3)으로 가정하고 수식 전개 \(\begin{matrix} w_{11} &amp; w_{12} &amp; w_{13} \\ w_{21} &amp; w_{22} &amp; w_{23} \\ \end{matrix}\) \(\left[ \begin{matrix} {\partial L \over \partial{w_{11}}} &amp; {\partial L \over \partial{w_{12}}} &amp; {\partial L \over \partial{w_{13}}} \\ {\partial L \over \partial{w_{21}}} &amp; {\partial L \over \partial{w_{22}}} &amp; {\partial L \over \partial{w_{23}}} \\ \end{matrix} \right]\)</p><p>이를 python으로 구현하면 다음과 같다. (초기 가중치 설정에 관련한 문제는 여기에서는 다루지 않고 뒤에서 다룰 예정)</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">common.functions</span> <span class="kn">import</span> <span class="n">softmax</span><span class="p">,</span> <span class="n">cross_entropy_error</span>
<span class="kn">from</span> <span class="nn">common.gradient</span> <span class="kn">import</span> <span class="n">numerical_gradient</span>

<span class="k">class</span> <span class="nc">simpleNet</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">W</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="n">softmax</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">cross_entropy_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">loss</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="n">net</span> <span class="o">=</span> <span class="n">simpleNet</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">net</span><span class="p">.</span><span class="n">W</span><span class="p">)</span> <span class="c1"># 가중치 매개변수
</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">])</span>
<span class="n">p</span><span class="o">=</span><span class="n">net</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

<span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="c1"># 최댓값을 갖는 인덱스
</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="c1"># 정답 레이블
</span><span class="n">net</span><span class="p">.</span><span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre>[[-2.07245772 -0.56657407 -1.66994278]
 [ 0.33661394  1.13914085  1.04237842]]
[-0.94052209  0.68528232 -0.06382508]





1.2616562177357782
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">W</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">net</span><span class="p">.</span><span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
      
      
<span class="n">dw</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">net</span><span class="p">.</span><span class="n">W</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">dw</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>[[ 0.25810928  0.03812922 -0.2962385 ]
 [ 0.38716392  0.05719382 -0.44435774]]
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">w</span><span class="p">:</span> <span class="n">net</span><span class="p">.</span><span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">dw</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">net</span><span class="p">.</span><span class="n">W</span><span class="p">)</span>
</pre></table></code></div></div><h2 id="45-학습-알고리즘의-구현"><span class="mr-2">4.5 학습 알고리즘의 구현</span><a href="#45-학습-알고리즘의-구현" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>경사하강법을 사용하여 가중치를 갱신한다. 이 때 데이터를 미니배치로 무작위로 선정하기 때문에</p><p>확률적 경사하강법(stocastic gradient descent)라 한다. 보통 SGD로 사용</p><p>mnist 데이터를 이용한 신경망 모델링</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">common.functions</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">common.gradient</span> <span class="kn">import</span> <span class="n">numerical_gradient</span>

<span class="k">class</span> <span class="nc">TwoLayerNet</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span>
                <span class="n">weight_init_std</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">):</span>
        
        <span class="c1"># 가중치 초기화
</span>        
        <span class="bp">self</span><span class="p">.</span><span class="n">params</span> <span class="o">=</span><span class="p">{}</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'W1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">weight_init_std</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'W2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">weight_init_std</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">output_size</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">W1</span><span class="p">,</span> <span class="n">W2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">"W1"</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">"W2"</span><span class="p">]</span>
        <span class="n">b1</span><span class="p">,</span> <span class="n">b2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b1'</span><span class="p">],</span>  <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b2'</span><span class="p">]</span>
        
        <span class="n">a1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W1</span><span class="p">)</span> <span class="o">+</span> <span class="n">b1</span>
        <span class="n">z1</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">a1</span><span class="p">)</span>
        <span class="n">a2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">z1</span><span class="p">,</span> <span class="n">W2</span><span class="p">)</span> <span class="o">+</span> <span class="n">b2</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">a2</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">y</span>
    
    <span class="c1"># x 입력 데이터 , t: 정답 레이블
</span>    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="n">y</span><span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">cross_entropy_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
        
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">accuracy</span>
        
    <span class="k">def</span> <span class="nf">numerical_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="n">loss_W</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">W</span><span class="p">:</span> <span class="bp">self</span><span class="p">.</span><span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        
        <span class="n">grads</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'W1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">loss_W</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">"W1"</span><span class="p">])</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'b1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">loss_W</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">"b1"</span><span class="p">])</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'W2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">loss_W</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">"W2"</span><span class="p">])</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'b2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">loss_W</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">"b2"</span><span class="p">])</span>
        
        <span class="k">return</span> <span class="n">grads</span>                
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">net</span> <span class="o">=</span> <span class="n">TwoLayerNet</span><span class="p">(</span><span class="n">input_size</span> <span class="o">=</span> <span class="mi">784</span><span class="p">,</span> <span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">output_size</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>

<span class="n">net</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'W1'</span><span class="p">].</span><span class="n">shape</span>
<span class="n">net</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b1'</span><span class="p">].</span><span class="n">shape</span>
<span class="n">net</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'W2'</span><span class="p">].</span><span class="n">shape</span>
<span class="n">net</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b2'</span><span class="p">].</span><span class="n">shape</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>(10,)
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">net</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="n">grads</span> <span class="o">=</span> <span class="n">net</span><span class="p">.</span><span class="n">numerical_gradient</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="k">print</span><span class="p">(</span><span class="n">grads</span><span class="p">[</span><span class="s">'W1'</span><span class="p">].</span><span class="n">shape</span><span class="p">,</span>
<span class="n">grads</span><span class="p">[</span><span class="s">'b1'</span><span class="p">].</span><span class="n">shape</span><span class="p">,</span>
<span class="n">grads</span><span class="p">[</span><span class="s">'W2'</span><span class="p">].</span><span class="n">shape</span><span class="p">,</span>
<span class="n">grads</span><span class="p">[</span><span class="s">'b2'</span><span class="p">].</span><span class="n">shape</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>(784, 100) (100,) (100, 10) (10,)
</pre></table></code></div></div><p>미니 배치 학습의 구현</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">dataset.mnist</span> <span class="kn">import</span> <span class="n">load_mnist</span>
<span class="kn">from</span> <span class="nn">two_layer_net</span> <span class="kn">import</span> <span class="n">TwoLayerNet</span>


<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="n">normalize</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">one_hot_label</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>

<span class="n">train_loss_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># 하이퍼파라미터 세팅
</span>
<span class="n">iters_num</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">TwoLayerNet</span><span class="p">(</span><span class="n">input_size</span> <span class="o">=</span> <span class="mi">784</span><span class="p">,</span> <span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">output_size</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iters_num</span><span class="p">):</span>
    
    <span class="n">batch_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">x_batch</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>
    <span class="n">t_batch</span> <span class="o">=</span> <span class="n">t_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>
    
    <span class="n">grad</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><span class="n">numerical_gradient</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">(</span><span class="s">"W1"</span><span class="p">,</span><span class="s">"b1"</span><span class="p">,</span><span class="s">"W2"</span><span class="p">,</span><span class="s">"b2"</span><span class="p">):</span>
        <span class="n">network</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">-=</span> <span class="n">learning_rate</span><span class="o">*</span><span class="n">grad</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        
        
    <span class="n">loss</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><span class="n">loss</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">)</span>
    <span class="n">train_loss_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"iter_num"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Loss of model"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">iter_num</span><span class="p">,</span><span class="n">train_loss_list</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><h2 id="453-시험-데이터로-평가하기"><span class="mr-2">4.5.3 시험 데이터로 평가하기</span><a href="#453-시험-데이터로-평가하기" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>신경망 학습의 목표는 범용성의 확보! 따라서 훈련에 사용되지 않은 데이터를 통해 해당 모형을 평가하는 것이 중요</p><p>epoch =&gt; 하나의 단위 훈련 데이터를 미니배치를 통해 학습을 할 경우 해당 미니배치를 다 소진한다면 1epoch가 실행된 것임</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">dataset.mnist</span> <span class="kn">import</span> <span class="n">load_mnist</span>
<span class="kn">from</span> <span class="nn">two_layer_net</span> <span class="kn">import</span> <span class="n">TwoLayerNet</span>


<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="n">normalize</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">one_hot_label</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>

<span class="n">train_loss_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">tarin_acc_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_acc_list</span> <span class="o">=</span> <span class="p">[]</span>


<span class="c1"># 하이퍼파라미터 세팅
</span>
<span class="n">iters_num</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="c1"># 1에폭당 반복수
</span>
<span class="n">iter_per_epoch</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">train_size</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">network</span> <span class="o">=</span> <span class="n">TwoLayerNet</span><span class="p">(</span><span class="n">input_size</span> <span class="o">=</span> <span class="mi">784</span><span class="p">,</span> <span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">output_size</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iters_num</span><span class="p">):</span>
    
    <span class="n">batch_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">x_batch</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>
    <span class="n">t_batch</span> <span class="o">=</span> <span class="n">t_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>
    
    <span class="n">grad</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><span class="n">numerical_gradient</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">(</span><span class="s">"W1"</span><span class="p">,</span><span class="s">"b1"</span><span class="p">,</span><span class="s">"W2"</span><span class="p">,</span><span class="s">"b2"</span><span class="p">):</span>
        <span class="n">network</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">-=</span> <span class="n">learning_rate</span><span class="o">*</span><span class="n">grad</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        
        
    <span class="n">loss</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><span class="n">loss</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">)</span>
    <span class="n">train_loss_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">iter_per_epoch</span> <span class="o">==</span><span class="mi">0</span><span class="p">:</span>
        <span class="n">train_acc</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">)</span>
        <span class="n">test_acc</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span>
        <span class="n">train_acc_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_acc</span><span class="p">)</span>
        <span class="n">test_acc_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_acc</span><span class="p">)</span>
        
</pre></table></code></div></div><h2 id="46-정리"><span class="mr-2">4.6 정리</span><a href="#46-정리" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ol><li><p>기계학습에서는 train-set과 test-set으로 나누게 된다.</p><li><p>훈련 데이터의 범용성을 확인하기 위한 방법으로 test-set을 사용하게 된다.</p><li><p>신경망 모형의 지표로 손실함수를 사용하게 된다. 이 때 손실함수가 작은 것이 좋음</p><li><p>해석적 미분을 구현하기 어려우므로 수치미분을 사용한다. 다음장에서 오차역전파법을 통해 이를 개선할 예정</p><li><p>가중치 매개변수를 갱신하기 위해서 매개변수의 기울기를 이용하게 된다.</p></ol></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/ml/'>ML</a>, <a href='/categories/book-study/'>book_study</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/deep-learning/" class="post-tag no-text-decoration" >Deep_learning</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"></div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0+%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94+%EB%94%A5%EB%9F%AC%EB%8B%9D+Chapter04+-+Yh%27s+blog&url=https%3A%2F%2Fleeje008.github.io%2Fposts%2F%25EB%25B0%2591%25EB%25B0%2594%25EB%258B%25A5%25EB%25B6%2580%25ED%2584%25B0-%25EC%258B%259C%25EC%259E%2591%25ED%2595%2598%25EB%258A%2594-%25EB%2594%25A5%25EB%259F%25AC%25EB%258B%259D-Chapter04%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0+%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94+%EB%94%A5%EB%9F%AC%EB%8B%9D+Chapter04+-+Yh%27s+blog&u=https%3A%2F%2Fleeje008.github.io%2Fposts%2F%25EB%25B0%2591%25EB%25B0%2594%25EB%258B%25A5%25EB%25B6%2580%25ED%2584%25B0-%25EC%258B%259C%25EC%259E%2591%25ED%2595%2598%25EB%258A%2594-%25EB%2594%25A5%25EB%259F%25AC%25EB%258B%259D-Chapter04%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fleeje008.github.io%2Fposts%2F%25EB%25B0%2591%25EB%25B0%2594%25EB%258B%25A5%25EB%25B6%2580%25ED%2584%25B0-%25EC%258B%259C%25EC%259E%2591%25ED%2595%2598%25EB%258A%2594-%25EB%2594%25A5%25EB%259F%25AC%25EB%258B%259D-Chapter04%2F&text=%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0+%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94+%EB%94%A5%EB%9F%AC%EB%8B%9D+Chapter04+-+Yh%27s+blog" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div><script src="https://utteranc.es/client.js" repo="leeje008/leeje008.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter02/">밑바닥부터 시작하는 딥러닝 Chapter02</a><li><a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter03/">밑바닥부터 시작하는 딥러닝 Chapter03</a><li><a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter04/">밑바닥부터 시작하는 딥러닝 Chapter04</a><li><a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter06/">밑바닥부터 시작하는 딥러닝 Chapter06</a><li><a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter07/">밑바닥부터 시작하는 딥러닝 Chapter07</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/deep-learning/">Deep_learning</a> <a class="post-tag" href="/tags/subject-project/">subject_project</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4"><div id="related-posts" class="mb-2 mb-sm-4"><h3 class="pt-2 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter02/"><div class="card-body"> <em class="small" data-ts="1636815600" data-df="ll" > Nov 14, 2021 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>밑바닥부터 시작하는 딥러닝 Chapter02</h3><div class="text-muted small"><p> 퍼셉트론 퍼셉트론 perceptron 알고리즘. 프랑크 로젠블라트가 1957년 고안한 알고리즘이고, 신경망(딥러닝)의 기원이 되는 알고리즘이다. 퍼셉트론은 딥러닝으로 나아가는 데 중요한 아이디어를 준다. 퍼셉트론 다수의 신호를 입력으로 하나의 신호를 출력한다. 신호 : 전류나 강물처럼 흐름 1을 신호가 흐른다. 0을 신호가 흐...</p></div></div></a></div><div class="card"> <a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter03/"><div class="card-body"> <em class="small" data-ts="1636815600" data-df="ll" > Nov 14, 2021 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>밑바닥부터 시작하는 딥러닝 Chapter03</h3><div class="text-muted small"><p> 신경망 가중치 매개변수의 적절한 값을 데이터에서 자동으로 학습하는 능력이 신경망의 중요한 성질이다. 신경망의 개요, 신경망이 입력 데이터가 무엇인지 식별하는 처리 과정을 알아보자. 퍼셉트론에서 신경망으로 퍼셉트론과 다른 점으로 신경망 구조를 살펴보자. 신경망의 예 신경망 그림을 참고한다. 가장 왼쪽 줄을 입력층, 가장 오른쪽 줄을 출력층, ...</p></div></div></a></div><div class="card"> <a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter06/"><div class="card-body"> <em class="small" data-ts="1637766000" data-df="ll" > Nov 25, 2021 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>밑바닥부터 시작하는 딥러닝 Chapter06</h3><div class="text-muted small"><p> Chapter 6 학습 관련 기술들 딥러닝 학습 효율, 정확도 개선 방법 가중치 매개변수 최적값 탐색하는 최적화 방법 가중치 매개변수 초깃값 하이퍼파라미터 설정 방법 오버피팅 대응책 가중치 감소 드롭아웃 배치 정규화 6.1 매개변수 갱신 신경망 학습의 목표는 매개변수의 최적값을 찾...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter03/" class="btn btn-outline-primary" prompt="Older"><p>밑바닥부터 시작하는 딥러닝 Chapter03</p></a> <a href="/posts/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-Chapter05/" class="btn btn-outline-primary" prompt="Newer"><p>밑바닥부터 시작하는 딥러닝 Chapter05</p></a></div></div></div><footer class="row pl-3 pr-3"><div class="col-12 d-flex justify-content-between align-items-center text-muted pl-0 pr-0"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://github.com/leeje008">Koyounghun</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">All rights reserved</span></p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/deep-learning/">Deep_learning</a> <a class="post-tag" href="/tags/subject-project/">subject_project</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/ko.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script>
